{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memanggil Library Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame & Series\n",
    "\n",
    "Di Pandas terdapat 2 kelas data baru yang digunakan sebagai struktur dari spreadsheet:\n",
    "\n",
    "Series: satu kolom bagian dari tabel dataframe yang merupakan 1 dimensional numpy array sebagai basis datanya, terdiri dari 1 tipe data (integer, string, float, dll).\n",
    "DataFrame: gabungan dari Series, berbentuk rectangular data yang merupakan tabel spreadsheet itu sendiri (karena dibentuk dari banyak Series, tiap Series biasanya punya 1 tipe data, yang artinya 1 dataframe bisa memiliki banyak tipe data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series:\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "5    6\n",
      "dtype: int64\n",
      "DataFrame:\n",
      "   0  1  2\n",
      "0  1  2  3\n",
      "1  a  b  c\n",
      "2  3  4  5\n",
      "3  d  4  6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Series\n",
    "number_list = pd.Series([1,2,3,4,5,6])\n",
    "print(\"Series:\")\n",
    "print(number_list)\n",
    "# DataFrame\n",
    "matrix = [[1,2,3],\n",
    "          ['a', 'b', 'c'],\n",
    "          [3,4,5],\n",
    "          ['d', 4, 6]]\n",
    "matrix_list = pd.DataFrame(matrix)\n",
    "print(\"DataFrame:\")\n",
    "print(matrix_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atribut DataFrame & Series - Part 1\n",
    "\n",
    "Method Python in pandas\n",
    "\n",
    "1. Method .info()\n",
    "\n",
    "Method .info() digunakan untuk mengecek kolom apa yang membentuk dataframe itu, data types, berapa yang non null, dll. Method ini tidak dapat digunakan pada series, hanya pada dataframe saja.\n",
    "\n",
    "![](images/34.png)\n",
    "\n",
    "Output di console untuk penggunaan method .info() ini adalah:\n",
    "\n",
    "![](images/35.png)\n",
    "\n",
    "2. Attribute .shape\n",
    "\n",
    "Attribute .shape digunakan untuk mengetahui berapa baris dan kolom, hasilnya dalam format tuple (baris, kolom).\n",
    "\n",
    "![](images/36.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .shape ini adalah:\n",
    "\n",
    "![](images/37.png)\n",
    "\n",
    "3. Attribute .dtypes\n",
    "\n",
    "Attribute .dtypes digunakan untuk mengetahui tipe data di tiap kolom. Tipe data object: kombinasi untuk berbagai tipe data (number & text, etc).\n",
    "\n",
    "![](images/38.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .dtypes ini adalah:\n",
    "\n",
    "![](images/39.png)\n",
    "\n",
    "4. Method .astype(nama_tipe_data)\n",
    "\n",
    "Method .astype(nama_tipe_data) untuk convert tipe data berdasarkan tipe data seperti: float, int, str, numpy.float, numpy.int ataupun numpy.datetime.\n",
    "\n",
    "![](images/40.png)\n",
    "\n",
    "Output di console untuk penggunaan method .astype() ini adalah:\n",
    "\n",
    "![](images/41.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Series\n",
    "number_list = pd.Series([1,2,3,4,5,6])\n",
    "# DataFrame\n",
    "matrix_list = pd.DataFrame([[1,2,3],\n",
    "\t\t\t\t            ['a','b','c'],\n",
    "\t\t\t\t            [3,4,5],\n",
    "\t\t\t\t            ['d',4,6]])\n",
    "# [1] method .info()\n",
    "print(\"[1] method .info()\")\n",
    "print(matrix_list.info())\n",
    "# [2] attribute .shape\n",
    "print(\"\\n[2] attribute .shape\")\n",
    "print(\"    Shape dari number_list:\", number_list.shape)\n",
    "print(\"    Shape dari matrix_list:\", matrix_list.shape)\n",
    "# [3] attribute .dtypes\n",
    "print(\"\\n[3] attribute .dtypes\")\n",
    "print(\"    Tipe data number_list:\", number_list.dtypes)\n",
    "print(\"    Tipe data matrix_list:\", matrix_list.dtypes)\n",
    "# [4] attribute .astype()\n",
    "print(\"\\n[4] method .astype()\")\n",
    "print(\"    Konversi number_list ke str:\", number_list.astype(\"str\"))\n",
    "print(\"    Konversi matrix_list ke str:\", matrix_list.astype(\"str\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atribut DataFrame & Series - Part 2\n",
    "\n",
    "5. Attribute .copy()\n",
    "\n",
    "Attribute .copy() digunakan melakukan duplikat, untuk disimpan di variable yang berbeda mungkin supaya tidak loading data lagi.\n",
    "\n",
    "![](images/42.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .copy() ini adalah:\n",
    "\n",
    "![](images/43.png)\n",
    "\n",
    "6. Attribute .to_list()\n",
    "\n",
    "Attribute .to_list() digunakan untuk mengubah series menjadi list dan tidak dapat digunakan untuk dataframe.\n",
    "\n",
    "![](images/44.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .to_list() ini adalah:\n",
    "\n",
    "![](images/45.png)\n",
    "\n",
    "7. Attribute .unique()\n",
    "\n",
    "Attribute .unique() digunakan menghasilkan nilai unik dari suatu kolom, hasilnya dalam bentuk numpy array. Attribute ini hanya digunakan pada series saja.\n",
    "\n",
    "![](images/46.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .unique() ini adalah:\n",
    "\n",
    "![](images/47.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Series\n",
    "number_list = pd.Series([1,2,3,4,5,6])\n",
    "# DataFrame\n",
    "matrix_list = pd.DataFrame([[1,2,3],\n",
    "\t\t\t\t            ['a','b','c'],\n",
    "\t\t\t\t            [3,4,5],\n",
    "\t\t\t\t            ['d',4,6]])\n",
    "# [5] attribute .copy()\n",
    "print(\"[5] attribute .copy()\")\n",
    "num_list = number_list.copy()\n",
    "print(\"    Copy number_list ke num_list:\", num_list)\n",
    "mtr_list = matrix_list.copy()\n",
    "print(\"    Copy matrix_list ke mtr_list:\", mtr_list)\t\n",
    "# [6] attribute .to_list()\n",
    "print(\"[6] attribute .to_list()\")\n",
    "print(number_list.to_list())\n",
    "# [7] attribute .unique()\n",
    "print(\"[7] attribute .unique()\")\n",
    "print(number_list.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atribut DataFrame & Series - Part 3\n",
    "\n",
    "8. Attribute .index\n",
    "\n",
    "Attribute .index digunakan untuk mencari index/key dari Series atau Dataframe.\n",
    "\n",
    "![](images/48.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .index ini adalah:\n",
    "\n",
    "![](images/49.png)\n",
    "\n",
    "9. Attribute .columns\n",
    "\n",
    "Attribute .columns digunakan untuk mengetahui apa saja kolom yang tersedia di dataframe tersebut (hanya digunakan untuk dataframe saja). \n",
    "\n",
    "![](images/50.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .columns ini adalah:\n",
    "\n",
    "![](images/51.png)\n",
    "\n",
    "10. Attribute .loc\n",
    "\n",
    "Attribute .loc digunakan slice dataframe atau series berdasarkan nama kolom dan/atau nama index.\n",
    "\n",
    "![](images/52.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .loc[] ini adalah:\n",
    "\n",
    "![](images/53.png)\n",
    "\n",
    "11. Attribute .iloc\n",
    "\n",
    "Attribute .iloc digunakan untuk slice dataframe atau series berdasarkan index kolom dan/atau index.\n",
    "\n",
    "![](images/54.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .iloc[] ini adalah:\n",
    "\n",
    "![](images/55.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] attribute .index\n",
      "    Index number_list: RangeIndex(start=0, stop=6, step=1)\n",
      "    Index matrix_list: RangeIndex(start=0, stop=4, step=1)\n",
      "[9] attribute .columns\n",
      "    Column matrix_list: RangeIndex(start=0, stop=3, step=1)\n",
      "[10] attribute .loc\n",
      "    .loc[0:1] pada number_list: 0    1\n",
      "1    2\n",
      "dtype: int64\n",
      "    .loc[0:1] pada matrix_list:    0  1  2\n",
      "0  1  2  3\n",
      "1  a  b  c\n",
      "[11] attribute .iloc\n",
      "    iloc[0:1] pada number_list: 0    1\n",
      "dtype: int64\n",
      "    iloc[0:1] pada matrix_list:    0  1  2\n",
      "0  1  2  3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Series\n",
    "number_list = pd.Series([1,2,3,4,5,6])\n",
    "# DataFrame\n",
    "matrix_list = pd.DataFrame([[1,2,3],\n",
    "\t\t\t\t            ['a','b','c'],\n",
    "\t\t\t\t            [3,4,5],\n",
    "\t\t\t\t            ['d',4,6]])\n",
    "# [8] attribute .index\n",
    "print(\"[8] attribute .index\")\n",
    "print(\"    Index number_list:\", number_list.index)\n",
    "print(\"    Index matrix_list:\", matrix_list.index)\t\n",
    "# [9] attribute .columns\n",
    "print(\"[9] attribute .columns\")\n",
    "print(\"    Column matrix_list:\", matrix_list.columns)\n",
    "# [10] attribute .loc\n",
    "print(\"[10] attribute .loc\")\n",
    "print(\"    .loc[0:1] pada number_list:\", number_list.loc[0:1])\n",
    "print(\"    .loc[0:1] pada matrix_list:\", matrix_list.loc[0:1])\n",
    "# [11] attribute .iloc\n",
    "print(\"[11] attribute .iloc\")\n",
    "print(\"    iloc[0:1] pada number_list:\", number_list.iloc[0:1])\n",
    "print(\"    iloc[0:1] pada matrix_list:\", matrix_list.iloc[0:1])\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Series & Dataframe from List\n",
    "\n",
    "Untuk membuat Series atau Dataframe bisa dari berbagai macam tipe data container/mapping di python, seperti list dan dictionary, maupun dari numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    a\n",
      "1    1\n",
      "2    3\n",
      "3    5\n",
      "4    c\n",
      "5    d\n",
      "dtype: object\n",
      "     float char   obj char\n",
      "dq     1.0    a     b    c\n",
      "lab    2.5    d     e    f\n",
      "kar    5.0    g     h    i\n",
      "lan    7.5    j  10.5    l\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Creating series from list\n",
    "ex_list = ['a',1,3,5,'c','d']\n",
    "ex_series = pd.Series(ex_list)\n",
    "print(ex_series)\n",
    "# Creating dataframe from list of list\n",
    "ex_list_of_list = [[1, 'a', 'b', 'c'],\n",
    "                   [2.5, 'd', 'e', 'f'],\n",
    "\t\t           [5, 'g', 'h', 'i'],\n",
    "\t\t           [7.5, 'j', 10.5, 'l']]\n",
    "index = ['dq', 'lab', 'kar', 'lan']\n",
    "cols = ['float', 'char', 'obj', 'char']\n",
    "ex_df = pd.DataFrame(ex_list_of_list, index=index, columns=cols)\n",
    "print(ex_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Series & Dataframe from Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    a\n",
      "2    b\n",
      "3    c\n",
      "dtype: object\n",
      "   1  2  4\n",
      "0  a  b  2\n",
      "1  b  c  3\n",
      "2  c  d  z\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Creating series from dictionary\n",
    "dict_series = {'1' : 'a',\n",
    "\t\t\t   '2' : 'b',\n",
    "\t\t\t   '3' : 'c'}\n",
    "ex_series = pd.Series(dict_series)\n",
    "print(ex_series)\n",
    "# Creating dataframe from dictionary\n",
    "df_series = {'1' : ['a', 'b', 'c'],\n",
    "             '2' : ['b', 'c', 'd'], \n",
    "             '4' : [2, 3, 'z']}\n",
    "ex_df = pd.DataFrame(df_series)\n",
    "print(ex_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Series & Dataframe from Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "5    6\n",
      "6    6\n",
      "7    7\n",
      "dtype: int32\n",
      "   0  1  2   3\n",
      "0  1  2  3   5\n",
      "1  5  6  7   8\n",
      "2  a  b  c  10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Creating series from numpy array (1D)\n",
    "arr_series = np.array([1,2,3,4,5,6,6,7])\n",
    "ex_series = pd.Series(arr_series)\n",
    "print(ex_series)\n",
    "# Creating dataframe from numpy array (2D)\n",
    "arr_df = np.array([[1, 2, 3, 5],\n",
    "                   [5, 6, 7, 8],\n",
    "                   ['a', 'b', 'c', 10]])\n",
    "ex_df = pd.DataFrame(arr_df)\n",
    "print(ex_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas menyediakan berbagai method untuk membaca file tersebut hanya dengan dipanggil method itu, code yang lebih simple dan loading yang lebih, tentu saja output nya dapat berupa Series atau Dataframe.\n",
    "\n",
    "Terdapat sangat banyak file yang dapat dibaca/dapat disimpan oleh Pandas, tapi ada beberapa file yang paling umum dan sering digunakan oleh praktisi data seperti berikut ini:\n",
    "\n",
    "- CSV (Comma Separated Values), antar data dalam satu baris dipisahkan oleh comma, \",\".\n",
    "- TSV (Tab Separated Values), antar data dalam satu baris dipisahkan oleh \"Tab\".\n",
    "- Excel\n",
    "- Google BigQuery\n",
    "- SQL Query\n",
    "- JSON (Java Script Object Notation)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset - CSV dan TSV\n",
    "\n",
    "CSV dan TSV pada hakikatnya adalah tipe data text dengan perbedaan terletak pada pemisah antar data dalam satu baris. Pada file CSV, antar data dalam satu baris dipisahkan oleh comma, \",\". Namun, pada file TSV antar data dalam satu baris dipisahkan oleh \"Tab\".\n",
    "\n",
    "Fungsi .read_csv() digunakan untuk membaca file yang value-nya dipisahkan oleh comma (default), terkadang pemisah value-nya bisa di set ‘\\t’ untuk file tsv (tab separated values).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  order_date  customer_id             city     province product_id  \\\n",
      "0   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P0648   \n",
      "1   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3826   \n",
      "2   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1508   \n",
      "\n",
      "     brand  quantity  item_price  \n",
      "0  BRAND_C         4     1934000  \n",
      "1  BRAND_V         8      604000  \n",
      "2  BRAND_G        12      747000  \n",
      "   order_id  order_date  customer_id             city     province product_id  \\\n",
      "0   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P0648   \n",
      "1   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3826   \n",
      "2   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1508   \n",
      "\n",
      "     brand  quantity  item_price  \n",
      "0  BRAND_C         4     1934000  \n",
      "1  BRAND_V         8      604000  \n",
      "2  BRAND_G        12      747000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# File CSV\n",
    "df_csv = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_csv.csv\")\n",
    "print(df_csv.head(3)) # Menampilkan 3 data teratas\n",
    "# File TSV\n",
    "df_tsv = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_tsv.tsv\", sep='\\t')\n",
    "print(df_tsv.head(3)) # Menampilkan 3 data teratas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset - Excel\n",
    "File Excel dengan ekstensi *.xls atau *.xlsx cukup banyak digunakan dalam menyimpan data. Pandas juga memiliki fitur untuk membaca file excel.\n",
    "\n",
    "Notes :\n",
    "\n",
    "Dataset : https://storage.googleapis.com/dqlab-dataset/sample_excel.xlsx\n",
    "\n",
    "Fungsi .read_excel() digunakan untuk membaca file excel menjadi dataframe pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\compat\\_optional.py:138\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=136'>137</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=137'>138</a>\u001b[0m     module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(name)\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=138'>139</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/importlib/__init__.py?line=124'>125</a>\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Program%20Files/Python310/lib/importlib/__init__.py?line=125'>126</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\PC\\DQlabtrack\\ADVANCED\\Python\\Data Manipulation with Pandas - Part 1.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/DQlabtrack/ADVANCED/Python/Data%20Manipulation%20with%20Pandas%20-%20Part%201.ipynb#ch0000020?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/DQlabtrack/ADVANCED/Python/Data%20Manipulation%20with%20Pandas%20-%20Part%201.ipynb#ch0000020?line=1'>2</a>\u001b[0m \u001b[39m# File xlsx dengan data di sheet \"test\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/PC/DQlabtrack/ADVANCED/Python/Data%20Manipulation%20with%20Pandas%20-%20Part%201.ipynb#ch0000020?line=2'>3</a>\u001b[0m df_excel \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_excel(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://storage.googleapis.com/dqlab-dataset/sample_excel.xlsx\u001b[39;49m\u001b[39m\"\u001b[39;49m, sheet_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/DQlabtrack/ADVANCED/Python/Data%20Manipulation%20with%20Pandas%20-%20Part%201.ipynb#ch0000020?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(df_excel\u001b[39m.\u001b[39mhead(\u001b[39m5\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\excel\\_base.py:457\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=454'>455</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=455'>456</a>\u001b[0m     should_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=456'>457</a>\u001b[0m     io \u001b[39m=\u001b[39m ExcelFile(io, storage_options\u001b[39m=\u001b[39;49mstorage_options, engine\u001b[39m=\u001b[39;49mengine)\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=457'>458</a>\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39mand\u001b[39;00m engine \u001b[39m!=\u001b[39m io\u001b[39m.\u001b[39mengine:\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=458'>459</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=459'>460</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=460'>461</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=461'>462</a>\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\excel\\_base.py:1419\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=1415'>1416</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine \u001b[39m=\u001b[39m engine\n\u001b[0;32m   <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=1416'>1417</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage_options \u001b[39m=\u001b[39m storage_options\n\u001b[1;32m-> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=1418'>1419</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engines[engine](\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_io, storage_options\u001b[39m=\u001b[39;49mstorage_options)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\excel\\_openpyxl.py:524\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=508'>509</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=509'>510</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=510'>511</a>\u001b[0m     filepath_or_buffer: FilePath \u001b[39m|\u001b[39m ReadBuffer[\u001b[39mbytes\u001b[39m],\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=511'>512</a>\u001b[0m     storage_options: StorageOptions \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=512'>513</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=513'>514</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=514'>515</a>\u001b[0m \u001b[39m    Reader using openpyxl engine.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=515'>516</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=521'>522</a>\u001b[0m \u001b[39m        passed to fsspec for appropriate URLs (see ``_get_filepath_or_buffer``)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=522'>523</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=523'>524</a>\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39;49m\u001b[39mopenpyxl\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=524'>525</a>\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(filepath_or_buffer, storage_options\u001b[39m=\u001b[39mstorage_options)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\compat\\_optional.py:141\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=138'>139</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=139'>140</a>\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=140'>141</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=141'>142</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=142'>143</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# File xlsx dengan data di sheet \"test\"\n",
    "df_excel = pd.read_excel(\"https://storage.googleapis.com/dqlab-dataset/sample_excel.xlsx\", sheet_name=\"test\")\n",
    "print(df_excel.head(5)) # Menampilkan 4 data teratas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset - JSON\n",
    "Method .read_json() digunakan untuk membaca URL API yang formatnya JSON dan mengubahnya menjadi dataframe pandas. Method ini dapat digunakan seperti yang dicontohkan berikut ini:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                data          dt          ts\n",
      "0  {'location': 'US', 'confirmed': 3363056, 'deat...  07-14-2020  1594684800\n",
      "1  {'location': 'Brazil', 'confirmed': 1884967, '...  07-14-2020  1594684800\n",
      "2  {'location': 'India', 'confirmed': 906752, 'de...  07-14-2020  1594684800\n",
      "3  {'location': 'Russia', 'confirmed': 732547, 'd...  07-14-2020  1594684800\n",
      "4  {'location': 'Peru', 'confirmed': 330123, 'dea...  07-14-2020  1594684800\n",
      "5  {'location': 'Chile', 'confirmed': 317657, 'de...  07-14-2020  1594684800\n",
      "6  {'location': 'Mexico', 'confirmed': 304435, 'd...  07-14-2020  1594684800\n",
      "7  {'location': 'United Kingdom', 'confirmed': 29...  07-14-2020  1594684800\n",
      "8  {'location': 'South Africa', 'confirmed': 2877...  07-14-2020  1594684800\n",
      "9  {'location': 'Iran', 'confirmed': 259652, 'dea...  07-14-2020  1594684800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# File JSON\n",
    "url = \"https://storage.googleapis.com/dqlab-dataset/covid2019-api-herokuapp-v2.json\"\n",
    "df_json = pd.read_json(url)\n",
    "print(df_json.head(10)) # Menampilkan 10 data teratas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset - SQL\n",
    "Fungsi .read_sql() atau .read_sql_query() digunakan untuk membaca query dari database dan translate menjadi pandas dataframe, contoh case ini database sqlite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contoh penggunaannya:\n",
    "\n",
    "![](images/56.png)\n",
    "\n",
    "Jika menggunakan .read_sql_query\n",
    "\n",
    "![](images/57.png)\n",
    "\n",
    "Output:\n",
    "\n",
    "![](images/58.png)\n",
    "\n",
    "Jika menggunakan .read_sql\n",
    "\n",
    "![](images/59.png)\n",
    "\n",
    "Output:\n",
    "\n",
    "![](images/60.png)\n",
    "\n",
    "Terlihat keduanya menghasilkan output yang sama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loan_id  account_id        date  amount  duration  payments status\n",
      "0     4959           2  1994-01-05   80952        24    3373.0      A\n",
      "1     4961          19  1996-04-29   30276        12    2523.0      B\n",
      "2     4962          25  1997-12-08   30276        12    2523.0      A\n",
      "3     4967          37  1998-10-14  318480        60    5308.0      D\n",
      "4     4968          38  1998-04-19  110736        48    2307.0      C\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "my_conn = mysql.connector.connect(host = \"relational.fit.cvut.cz\",\n",
    "                                  port = 3306,\n",
    "                                  user = \"guest\",\n",
    "                                  password = \"relational\",\n",
    "                                  database = \"financial\",\n",
    "                                  use_pure = True)\n",
    "\n",
    "my_tabel = \"SELECT * FROM loan\"\n",
    "\n",
    "df = pd.read_sql(my_tabel, my_conn)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset - Google BigQuery\n",
    "Untuk data yang besar (big data), umumnya digunakan Google BigQuery. Layanan ini dapat digunakan jika telah memiliki Google BigQuery account.\n",
    "\n",
    " \n",
    "\n",
    "Fungsi .read_gbq() digunakan untuk membaca Google BigQuery table menjadi dataframe pandas.\n",
    "\n",
    "![](images/61.png)\n",
    "\n",
    "project_id=\"XXXXXXXX\" adalah ID dari Google BigQuery account.\n",
    "\n",
    "Output-nya:\n",
    "\n",
    "![](images/62.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pandas-gbq'. pandas-gbq is required to load data from Google BigQuery. See the docs: https://pandas-gbq.readthedocs.io. Use pip or conda to install pandas-gbq.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\compat\\_optional.py:138\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=136'>137</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=137'>138</a>\u001b[0m     module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(name)\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=138'>139</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/importlib/__init__.py?line=124'>125</a>\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Program%20Files/Python310/lib/importlib/__init__.py?line=125'>126</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas_gbq'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\PC\\DQlabtrack\\ADVANCED\\Python\\Data Manipulation with Pandas - Part 1.ipynb Cell 28'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/DQlabtrack/ADVANCED/Python/Data%20Manipulation%20with%20Pandas%20-%20Part%201.ipynb#ch0000028?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/DQlabtrack/ADVANCED/Python/Data%20Manipulation%20with%20Pandas%20-%20Part%201.ipynb#ch0000028?line=2'>3</a>\u001b[0m table \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSELECT * FROM bigquery-public-data.covid19_jhu_case_eu.summary\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/PC/DQlabtrack/ADVANCED/Python/Data%20Manipulation%20with%20Pandas%20-%20Part%201.ipynb#ch0000028?line=4'>5</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_gbq(table, project_id\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mXXXXXXXX\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/DQlabtrack/ADVANCED/Python/Data%20Manipulation%20with%20Pandas%20-%20Part%201.ipynb#ch0000028?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(df)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\gbq.py:170\u001b[0m, in \u001b[0;36mread_gbq\u001b[1;34m(query, project_id, index_col, col_order, reauth, auth_local_webserver, dialect, location, configuration, credentials, use_bqstorage_api, max_results, progress_bar_type)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_gbq\u001b[39m(\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=26'>27</a>\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=27'>28</a>\u001b[0m     project_id: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=38'>39</a>\u001b[0m     progress_bar_type: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=39'>40</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=40'>41</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=41'>42</a>\u001b[0m \u001b[39m    Load data from Google BigQuery.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=42'>43</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=167'>168</a>\u001b[0m \u001b[39m    DataFrame.to_gbq : Write a DataFrame to Google BigQuery.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=168'>169</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=169'>170</a>\u001b[0m     pandas_gbq \u001b[39m=\u001b[39m _try_import()\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=171'>172</a>\u001b[0m     kwargs: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mbool\u001b[39m \u001b[39m|\u001b[39m \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m] \u001b[39m=\u001b[39m {}\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=173'>174</a>\u001b[0m     \u001b[39m# START: new kwargs.  Don't populate unless explicitly set.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\gbq.py:22\u001b[0m, in \u001b[0;36m_try_import\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_import\u001b[39m():\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=15'>16</a>\u001b[0m     \u001b[39m# since pandas is a dependency of pandas-gbq\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=16'>17</a>\u001b[0m     \u001b[39m# we need to import on first use\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=17'>18</a>\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=18'>19</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpandas-gbq is required to load data from Google BigQuery. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=19'>20</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee the docs: https://pandas-gbq.readthedocs.io.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=20'>21</a>\u001b[0m     )\n\u001b[1;32m---> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=21'>22</a>\u001b[0m     pandas_gbq \u001b[39m=\u001b[39m import_optional_dependency(\u001b[39m\"\u001b[39;49m\u001b[39mpandas_gbq\u001b[39;49m\u001b[39m\"\u001b[39;49m, extra\u001b[39m=\u001b[39;49mmsg)\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=22'>23</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_gbq\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\compat\\_optional.py:141\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=138'>139</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=139'>140</a>\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=140'>141</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=141'>142</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=142'>143</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'pandas-gbq'. pandas-gbq is required to load data from Google BigQuery. See the docs: https://pandas-gbq.readthedocs.io. Use pip or conda to install pandas-gbq."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table = \"SELECT * FROM bigquery-public-data.covid19_jhu_case_eu.summary\"\n",
    "\n",
    "df = pd.read_gbq(table, project_id=\"XXXXXXXX\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Dataset\n",
    "Dalam bekerja sebagai data scientist/analis setelah dilakukan data cleaning dataset yang sudah rapi tentunya disimpan terlebih dahulu ke dalam media penyimpanan.  \n",
    "\n",
    " \n",
    "\n",
    "Pandas menyediakan fitur demikian secara ringkas melalui penerapan method pada dataframe/series yang ditabelkan berikut ini:\n",
    "\n",
    "Method\n",
    "\n",
    "Code\n",
    "\n",
    ".to_csv()\n",
    "\n",
    "→ digunakan untuk export dataframe kembali ke csv atau tsv\t\n",
    "CSV\n",
    "\n",
    "df.to_csv(\"csv1.csv\", index=False)\n",
    "TSV\n",
    "\n",
    "df.to_csv(\"tsv1.tsv\", index=False, sep='\\t')\n",
    ".to_clipboard()\n",
    "\n",
    "→ export dataframe menjadi bahan copy jadi nanti bisa tinggal klik paste di excel atau google sheets\n",
    "\n",
    "df.to_clipboard()\n",
    ".to_excel()\n",
    "\n",
    "→ export dataframe menjadi file excel\n",
    "\n",
    "df_excel.to_excel(\"xlsx1.xlsx\", index=False)\n",
    ".to_gbq()\n",
    "\n",
    "→ export dataframe menjadi table di Google BigQuery\n",
    "\n",
    "df.to_gbq(\"temp.test\", project_id=\"XXXXXX\", if_exists=\"fail\")\n",
    "temp: nama dataset,\n",
    "\n",
    "test: nama table\n",
    "\n",
    "if_exists: ketika tabel dengan dataset.table_name yang sama sudah ada, apa action yang ingin dilakukan\n",
    "\n",
    "(\"fail\": tidak melakukan apa-apa,\n",
    "\n",
    " \"replace': membuang tabel yang sudah ada dan mengganti yang baru,\n",
    "\n",
    " \"append\": menambah baris di tabel tersebut dengan data yang baru\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head & Tail\n",
    "Seperti yang telah dipelajari sebelumnya bahwa ada method .head yang diterapkan pada suatu variabel bertipe pandas dataframe/series.\n",
    "\n",
    "Method .head ditujukan untuk membatasi tampilan jumlah baris teratas dari dataset. Sementara itu, method .tail ditujukan untuk membatasi jumlah baris terbawah dari dataset.\n",
    "\n",
    "Secara umum kedua method ini memiliki bentuk\n",
    "\n",
    "[nama_dataframe].head(n) \n",
    "dan \n",
    "\n",
    "[nama_dataframe].tail(n)\n",
    "dengan n merupakan jumlah baris yang akan ditampilkan, jika tidak disebutkan n = 5 (sebagai nilai default dari n). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiga data teratas:\n",
      "    order_id  order_date  customer_id             city     province product_id  \\\n",
      "0   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P0648   \n",
      "1   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3826   \n",
      "2   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1508   \n",
      "\n",
      "     brand  quantity  item_price  \n",
      "0  BRAND_C         4     1934000  \n",
      "1  BRAND_V         8      604000  \n",
      "2  BRAND_G        12      747000  \n",
      "Tiga data terbawah:\n",
      "      order_id  order_date  customer_id      city          province product_id  \\\n",
      "98    1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P3354   \n",
      "99    1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P3357   \n",
      "100   1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P0422   \n",
      "\n",
      "       brand  quantity  item_price  \n",
      "98   BRAND_S        24      450000  \n",
      "99   BRAND_S        24      450000  \n",
      "100  BRAND_B         4     1325000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file sample_csv.csv\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_csv.csv\")\n",
    "# Tampilkan 3 data teratas\n",
    "print(\"Tiga data teratas:\\n\", df.head(3))\n",
    "# Tampilkan 3 data terbawah\n",
    "print(\"Tiga data terbawah:\\n\", df.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUIZ\n",
    "\n",
    "akukan analisis dengan menggunakan BigQuery karena ada beberapa data BigQuery public datasets yang informasinya akurat dan sudah banyak data point-nya sehingga sudah bisa digunakan.\n",
    "\n",
    "Tapi masalahnya, ada beberapa data adhoc yang bergantung tim lain yang belum terlalu melek data dan datanya masih disimpan dalam bentuk CSV.\n",
    "\n",
    "Bagaimana langkah efektif yang dapat diambil untuk melakukan analisis gabungan data dari BigQuery dan CSV?\n",
    "\n",
    " \n",
    "\n",
    "Hint: coba explore BigQuery public datasets dulu, kamu akan dapati data size yang besar (>1juta baris), akan susah kalau harus di export dan dilakukan analisis di excel.\n",
    "\n",
    "JAWABAN\n",
    "\n",
    "(a) Export BigQuery menggunakan pd.read_gbq, kemudian disimpan dalam CSV, lakukan analisis di excel\n",
    "\n",
    "(b) Upload data CSV ke BigQuery, lakukan analisis di dalam BigQuery/export to pandas menggunakan pd.read_gbq\n",
    "\n",
    "(c) Export data BigQuery menggunakan pd.read_gbq as dataframe, kemudian baca file csv menggunakan pd.read_csv dan akhirnya melakukan analisis gabungan di python\n",
    "\n",
    "(b) dan (c)\n",
    "\n",
    "Answers is b ,c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing - Part 1\n",
    "Index merupakan key identifier dari tiap row/column untuk Series atau Dataframe (sifatnya tidak mutable untuk masing-masing value tapi bisa diganti untuk semua value sekaligus).\n",
    "\n",
    "Jika tidak disediakan, pandas akan membuat kolom index default secara otomatis sebagai bilangan bulat (integer) dari 0 sampai range jumlah baris data tersebut.\n",
    "\n",
    "Kolom index dapat terdiri dari:\n",
    "\n",
    "satu kolom (single index), atau\n",
    "multiple kolom (disebut dengan hierarchical indexing).\n",
    "Index dengan multiple kolom ini terjadi karena unique identifier tidak dapat dicapai hanya dengan set index di 1 kolom saja sehingga membutuhkan beberapa kolom yang menjadikan tiap row menjadi unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing - Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : RangeIndex(start=0, stop=101, step=1)\n",
      "Columns: Index(['order_id', 'order_date', 'customer_id', 'city', 'province',\n",
      "       'product_id', 'brand', 'quantity', 'item_price'],\n",
      "      dtype='object')\n",
      "     order_id  order_date  customer_id      city          province product_id  \\\n",
      "96    1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P3388   \n",
      "97    1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P3082   \n",
      "98    1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P3354   \n",
      "99    1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P3357   \n",
      "100   1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P0422   \n",
      "\n",
      "       brand  quantity  item_price  \n",
      "96   BRAND_S        10      450000  \n",
      "97   BRAND_R        18     1045000  \n",
      "98   BRAND_S        24      450000  \n",
      "99   BRAND_S        24      450000  \n",
      "100  BRAND_B         4     1325000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file TSV sample_tsv.tsv\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_tsv.tsv\", sep=\"\\t\")\n",
    "# Index dari df\n",
    "print(\"Index :\", df.index)\n",
    "# Column dari df\n",
    "print(\"Columns:\", df.columns)\n",
    "\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing - Part 3\n",
    "Di sub bab sebelumnya telah dibahas terkait single index, tentunya pada sub bab ini akan bahas multi index atau disebut juga dengan hierarchical indexing.\n",
    "\n",
    "Untuk membuat multi index (hierarchical indexing) dengan pandas diperlukan kolom-kolom mana saja yang perlu disusun agar index dari dataframe menjadi sebuah hirarki yang kemudian dapat dikenali.\n",
    "\n",
    " \n",
    "\n",
    "Pada sub bab sebelumnya telah diberikan nama-nama kolom dari dataframe yang telah dibaca, yaitu:\n",
    "\n",
    "![](images/63.png)\n",
    "\n",
    "dengan output\n",
    "\n",
    "![](images/64.png)\n",
    "\n",
    "Selanjutnya akan membuat multi index dengan menggunakan kolom 'order_id', 'customer_id', 'product_id', dan 'order_date' dengan menggunakan method .set_index(). Mari perhatikan contoh kode yang diberikan berikut ini:\n",
    "\n",
    "![](images/65.png)\n",
    "\n",
    "berikut hasil tampilan dataframe df_x-nya:\n",
    "\n",
    "![](images/66.png)\n",
    "\n",
    "Untuk melihat multi index yang telah diset dapat dilakukan dengan:\n",
    "\n",
    "![](images/67.png)\n",
    "\n",
    "yang memberikan output:\n",
    "\n",
    "![](images/68.png)\n",
    "\n",
    "Perlu diketahui bahwa kumpulan index dari multi index adalah list dari banyak tuples, tuples-nya merupakan kombinasi yang ada dari gabungan index-index tersebut. Dari multi index tersebut juga terdapat atribut levels yang menunjukkan urutan index, dalam case ini 'order_id' > 'customer_id' > 'product_id' > 'order_date'.\n",
    "\n",
    "![](images/69.png)\n",
    "\n",
    "yang menghasilkan output berupa:\n",
    "\n",
    "![](images/70.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_date : Index(['2019-01-01'], dtype='object', name='order_date')\n",
      "city : Index(['Bogor', 'Jakarta Pusat', 'Jakarta Selatan', 'Jakarta Utara',\n",
      "       'Makassar', 'Malang', 'Surabaya', 'Tangerang'],\n",
      "      dtype='object', name='city')\n",
      "customer_id : Int64Index([12681, 13963, 15649, 17091, 17228, 17450, 17470, 17511, 17616,\n",
      "            18055],\n",
      "           dtype='int64', name='customer_id')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file TSV sample_tsv.tsv\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_tsv.tsv\", sep=\"\\t\")\n",
    "# Set multi index df\n",
    "df_x = df.set_index(['order_date', 'city', 'customer_id'])\n",
    "# Print nama dan level dari multi index\n",
    "for nama, level in zip(df_x.index.names, df_x.index.levels):\n",
    "    print(nama,':',level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           day number week type\n",
      "Monday              1   weekday\n",
      "Tuesday             2   weekday\n",
      "Wednesday           3   weekday\n",
      "Thursday            4   weekday\n",
      "Friday              5   weekday\n",
      "Saturday            6   weekend\n",
      "Sunday              7   weekend\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({ \"day number\" : [i for i in range(1,8)],\n",
    "                    \"week type\" : [\"weekday\" for i in range (5)] + [\"weekend\" for i in range (2)]}, index=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"])\n",
    "df.reset_index(drop=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing - Part 4\n",
    "Terdapat beberapa cara untuk membuat index, salah satunya adalah seperti yang telah dilakukan pada sub bab sebelumnya dengan menggunakan method .set_index().\n",
    "\n",
    "Di sub bab ini akan menggunakan assignment untuk menset index dari suatu dataframe. Untuk itu file \"sample_excel.xlsx\" yang digunakan. Perhatikan code berikut!\n",
    "\n",
    "![](images/71.png)\n",
    "\n",
    "maka Outputnya\n",
    "\n",
    "![](images/72.png)\n",
    "\n",
    "Note:\n",
    "\n",
    "- Cara yang ditunjukkan oleh baris ketujuh (ke-7) pada code editor di atas hanya berlaku jika index yang di-assign tersebut memiliki panjang yang sama dengan jumlah \n",
    "baris dari dataframe.\n",
    "- Jika ingin kembalikan dataframe ke index default-nya yaitu dari 0 s/d jumlah baris data - 1, maka dapat menggunakan method .reset_index(drop=True), argument drop=True bertujuan untuk menghapus index lama. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe awal:\n",
      "    order_id  order_date  customer_id             city     province product_id  \\\n",
      "0   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P0648   \n",
      "1   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3826   \n",
      "2   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1508   \n",
      "3   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P0520   \n",
      "4   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1513   \n",
      "5   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3911   \n",
      "6   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1780   \n",
      "7   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3132   \n",
      "8   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1342   \n",
      "9   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P2556   \n",
      "\n",
      "     brand  quantity  item_price  \n",
      "0  BRAND_C         4     1934000  \n",
      "1  BRAND_V         8      604000  \n",
      "2  BRAND_G        12      747000  \n",
      "3  BRAND_B        12      450000  \n",
      "4  BRAND_G         3     1500000  \n",
      "5  BRAND_V         3     2095000  \n",
      "6  BRAND_H         3     2095000  \n",
      "7  BRAND_S         3     1745000  \n",
      "8  BRAND_F         6     1045000  \n",
      "9  BRAND_P         6     1045000  \n",
      "Dataframe dengan index baru:\n",
      "                order_id  order_date  customer_id             city  \\\n",
      "Pesanan ke-1    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-2    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-3    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-4    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-5    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-6    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-7    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-8    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-9    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-10   1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "\n",
      "                  province product_id    brand  quantity  item_price  \n",
      "Pesanan ke-1   DKI Jakarta      P0648  BRAND_C         4     1934000  \n",
      "Pesanan ke-2   DKI Jakarta      P3826  BRAND_V         8      604000  \n",
      "Pesanan ke-3   DKI Jakarta      P1508  BRAND_G        12      747000  \n",
      "Pesanan ke-4   DKI Jakarta      P0520  BRAND_B        12      450000  \n",
      "Pesanan ke-5   DKI Jakarta      P1513  BRAND_G         3     1500000  \n",
      "Pesanan ke-6   DKI Jakarta      P3911  BRAND_V         3     2095000  \n",
      "Pesanan ke-7   DKI Jakarta      P1780  BRAND_H         3     2095000  \n",
      "Pesanan ke-8   DKI Jakarta      P3132  BRAND_S         3     1745000  \n",
      "Pesanan ke-9   DKI Jakarta      P1342  BRAND_F         6     1045000  \n",
      "Pesanan ke-10  DKI Jakarta      P2556  BRAND_P         6     1045000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file sample_tsv.tsv untuk 10 baris pertama saja\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_tsv.tsv\", sep=\"\\t\", nrows=10)\n",
    "# Cetak data frame awal\n",
    "print(\"Dataframe awal:\\n\", df)\n",
    "# Set index baru\n",
    "df.index = [\"Pesanan ke-\" + str(i) for i in range(1, 11)]\n",
    "# Cetak data frame dengan index baru\n",
    "print(\"Dataframe dengan index baru:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing - Part 5\n",
    "Jika file yang akan dibaca melalui penggunaan library pandas dapat di-preview terlebih dahulu struktur datanya maka melalui fungsi yang ditujukan untuk membaca file dapat diset mana kolom yang akan dijadikan index.\n",
    "\n",
    " \n",
    "\n",
    "Fitur ini telah dimiliki oleh setiap fungsi yang digunakan dalam membaca data dengan pandas, yaitu penggunaan argumen index_col pada fungsi yang dimaksud. Untuk jelasnya dapat diperhatikan pada kode berikut ini.\n",
    "\n",
    "![](images/73.png)\n",
    "\n",
    "Dari dataset sample_csv.csv, sample_tsv.tsv, atau sample_excel.xlsx sudah tahu bahwa kolom dataset adalah 'order_id'; 'order_date'; 'customer_id'; 'city'; 'province'; 'product_id'; 'brand'; 'quantity'; and 'item_price'. Sehingga kode di atas digunakan langsung kolom 'order_date' pada saat membaca file-nya.\n",
    "\n",
    "maka outputnya :\n",
    "\n",
    "![](images/74.png)\n",
    "\n",
    "Terlihat bahwa kolom order_date sudah jadi index, dan tentunya jumlah kolom dataframe berkurang satu, yaitu menjadi delapan kolom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe:\n",
      "                      customer_id             city     province product_id  \\\n",
      "order_date order_id                                                         \n",
      "2019-01-01 1612339         18055  Jakarta Selatan  DKI Jakarta      P0648   \n",
      "           1612339         18055  Jakarta Selatan  DKI Jakarta      P3826   \n",
      "           1612339         18055  Jakarta Selatan  DKI Jakarta      P1508   \n",
      "           1612339         18055  Jakarta Selatan  DKI Jakarta      P0520   \n",
      "           1612339         18055  Jakarta Selatan  DKI Jakarta      P1513   \n",
      "           1612339         18055  Jakarta Selatan  DKI Jakarta      P3911   \n",
      "           1612339         18055  Jakarta Selatan  DKI Jakarta      P1780   \n",
      "           1612339         18055  Jakarta Selatan  DKI Jakarta      P3132   \n",
      "\n",
      "                       brand  quantity  item_price  \n",
      "order_date order_id                                 \n",
      "2019-01-01 1612339   BRAND_C         4     1934000  \n",
      "           1612339   BRAND_V         8      604000  \n",
      "           1612339   BRAND_G        12      747000  \n",
      "           1612339   BRAND_B        12      450000  \n",
      "           1612339   BRAND_G         3     1500000  \n",
      "           1612339   BRAND_V         3     2095000  \n",
      "           1612339   BRAND_H         3     2095000  \n",
      "           1612339   BRAND_S         3     1745000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file sample_tsv.tsv dan set lah index_col sesuai instruksi\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_tsv.tsv\", sep=\"\\t\", index_col=[\"order_date\", \"order_id\"])\n",
    "# Cetak data frame untuk 8 data teratas\n",
    "print(\"Dataframe:\\n\", df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'num']\n"
     ]
    }
   ],
   "source": [
    "df_week = pd.DataFrame({'day_number':[1,2,3,4,5,6,7],\n",
    "                        'week_type':['weekday' for i in range(5)] + ['weekend' for i in range(2)]\n",
    "                       })\n",
    "df_week_ix = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\n",
    "df_week.index = [df_week_ix, df_week['day_number'].to_list()]\n",
    "df_week.index.names = ['name','num']\n",
    "print(df_week.index.names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing - Part 1\n",
    "Seperti artinya slicing adalah cara untuk melakukan filter ke dataframe/series berdasarkan kriteria tertentu dari nilai kolomnya ataupun kriteria index-nya.\n",
    "\n",
    "Terdapat 2 cara paling terkenal untuk slicing dataframe, yaitu dengan menggunakan method .loc dan .iloc pada variabel bertipe pandas DataFrame/Series. Method .iloc ditujukan untuk proses slicing berdasarkan index berupa nilai integer tertentu. Akan tetapi akan lebih sering menggunakan dengan method .loc karena lebih fleksibel. \n",
    "\n",
    " \n",
    "\n",
    "Mari ikuti ilustrasi berikut ini.\n",
    "\n",
    "Dataset belum dilakukan indexing, jadi slicing berdasarkan nilai kolomnya. Untuk itu \"sample_csv.csv\" dibaca kembali dan dipraktikkan metode .loc[] dengan mengambil tanggal 1 Januari 2019 dari kolom order_date dan product_id nya adalah P2154 dan P2556.\n",
    "\n",
    "![](images/75.png)\n",
    "\n",
    "Output\n",
    "\n",
    "![](images/76.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        num_legs  num_wings\n",
      "falcon     False      False\n",
      "dog         True       True\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'num_legs': [2, 4], 'num_wings': [2, 0]},\n",
    "                  index=['falcon', 'dog'])\n",
    "print(df.isin([0, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice langsung berdasarkan kolom:\n",
      " Empty DataFrame\n",
      "Columns: [order_id, order_date, customer_id, city, province, product_id, brand, quantity, item_price]\n",
      "Index: []\n",
      "     order_id  order_date  customer_id             city          province  \\\n",
      "0     1612339  2019-01-01        18055  Jakarta Selatan       DKI Jakarta   \n",
      "1     1612339  2019-01-01        18055  Jakarta Selatan       DKI Jakarta   \n",
      "2     1612339  2019-01-01        18055  Jakarta Selatan       DKI Jakarta   \n",
      "3     1612339  2019-01-01        18055  Jakarta Selatan       DKI Jakarta   \n",
      "4     1612339  2019-01-01        18055  Jakarta Selatan       DKI Jakarta   \n",
      "..        ...         ...          ...              ...               ...   \n",
      "96    1612390  2019-01-01        12681         Makassar  Sulawesi Selatan   \n",
      "97    1612390  2019-01-01        12681         Makassar  Sulawesi Selatan   \n",
      "98    1612390  2019-01-01        12681         Makassar  Sulawesi Selatan   \n",
      "99    1612390  2019-01-01        12681         Makassar  Sulawesi Selatan   \n",
      "100   1612390  2019-01-01        12681         Makassar  Sulawesi Selatan   \n",
      "\n",
      "    product_id    brand  quantity  item_price  \n",
      "0        P0648  BRAND_C         4     1934000  \n",
      "1        P3826  BRAND_V         8      604000  \n",
      "2        P1508  BRAND_G        12      747000  \n",
      "3        P0520  BRAND_B        12      450000  \n",
      "4        P1513  BRAND_G         3     1500000  \n",
      "..         ...      ...       ...         ...  \n",
      "96       P3388  BRAND_S        10      450000  \n",
      "97       P3082  BRAND_R        18     1045000  \n",
      "98       P3354  BRAND_S        24      450000  \n",
      "99       P3357  BRAND_S        24      450000  \n",
      "100      P0422  BRAND_B         4     1325000  \n",
      "\n",
      "[101 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file sample_csv.csv\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_csv.csv\")\n",
    "# Slice langsung berdasarkan kolom\n",
    "df_slice = df.loc[(df[\"customer_id\"] == 18055) &\n",
    "\t\t          (df[\"product_id\"].isin([\"P0029\", \"P0040\", \"P0041\", \"P0116\", \"P0117\"]))\n",
    "\t\t\t\t ]\n",
    "print(\"Slice langsung berdasarkan kolom:\\n\", df_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    customer_id product_id\n",
      "0         18055      P0029\n",
      "1         18098      P0040\n",
      "2         19053      P0041\n",
      "3         18055      P0116\n",
      "4         19053      P0117\n",
      "5         18055      P0012\n",
      "6         18055      P0044\n",
      "7         18055      P0040\n",
      "8         18055      P0041\n",
      "9         18055      P0116\n",
      "10        18098      P0029\n",
      "11        18055      P0040\n",
      "12        18098      P0041\n",
      "13        19053      P0116\n",
      "14        18055      P0117\n",
      "15        18098      P0012\n",
      "Slice langsung berdasarkan kolom:\n",
      "     customer_id product_id\n",
      "0         18055      P0029\n",
      "3         18055      P0116\n",
      "7         18055      P0040\n",
      "8         18055      P0041\n",
      "9         18055      P0116\n",
      "11        18055      P0040\n",
      "14        18055      P0117\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'customer_id' : [18055, 18098, 19053 , 18055, 19053, 18055, 18055, 18055, 18055,18055\n",
    "                    , 18098, 18055, 18098, 19053, 18055, 18098], \n",
    "                    'product_id' : ['P0029', 'P0040', 'P0041', 'P0116', 'P0117', 'P0012', 'P0044', 'P0040',\n",
    "                    'P0041', 'P0116', 'P0029', 'P0040', 'P0041', 'P0116', 'P0117', 'P0012']})\n",
    "\n",
    "\n",
    "df_slice = df.loc[(df[\"customer_id\"] == 18055) &\n",
    "\t\t          (df[\"product_id\"].isin([\"P0029\", \"P0040\", \"P0041\", \"P0116\", \"P0117\"]))\n",
    "\t\t\t\t ]\n",
    "\n",
    "print(df)\n",
    "print(\"Slice langsung berdasarkan kolom:\\n\", df_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing - Part 2\n",
    "Dalam sub bab sebelumnya telah mempelajari bagaimana melakukan slicing/filtering dataset dengan menggunakan method .loc pada kolom dataset.\n",
    "\n",
    "Sekarang, menerapkan berdasarkan index. Tentu syaratnya adalah dataset sudah dilakukan indexing terlebih dahulu melalui penerapan method .set_index \n",
    "\n",
    " \n",
    "\n",
    "Cara 1: Gunakan method .loc seperti yang dicontohkan berikut:\n",
    "\n",
    "![](images/77.png)\n",
    "\n",
    "Output cara 1:\n",
    "\n",
    "![](images/78.png)\n",
    "\n",
    "Cara 2: Gunakan pd.IndexSlice sebagai varaibel untuk melakukan slicing index\n",
    "\n",
    "![](images/79.png)\n",
    "\n",
    "Output cara 2:\n",
    "\n",
    "![](images/80.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice df:\n",
      "                                 customer_id             city     province  \\\n",
      "order_date order_id product_id                                              \n",
      "2019-01-01 1612339  P2154             18055  Jakarta Selatan  DKI Jakarta   \n",
      "                    P2159             18055  Jakarta Selatan  DKI Jakarta   \n",
      "\n",
      "                                  brand  quantity  item_price  \n",
      "order_date order_id product_id                                 \n",
      "2019-01-01 1612339  P2154       BRAND_M         4     1745000  \n",
      "                    P2159       BRAND_M        24      310000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file sample_csv.csv\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_csv.csv\")\n",
    "# Set index dari df sesuai instruksi\n",
    "df = df.set_index([\"order_date\", \"order_id\", \"product_id\"])\n",
    "# Slice sesuai intruksi\n",
    "df_slice = df.loc[(\"2019-01-01\", 1612339, [\"P2154\", \"P2159\"]),:]\n",
    "print(\"Slice df:\\n\", df_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming - Part 1\n",
    "Transform adalah ketika mengubah dataset yang ada menjadi entitas baru, dapat dilakukan dengan:\n",
    "\n",
    "konversi dari satu data type ke data type yang lain,\n",
    "transpose dataframe,\n",
    "atau yang lainnya.\n",
    "Hal yang biasa dilakukan pertama kali setelah data dibaca adalah mengecek tipe data di setiap kolomnya apakah sesuai dengan representasinya. Untuk itu dapat menggunakan atribut .dtypes pada dataframe yang telah kita baca tadi,\n",
    "\n",
    "[nama_dataframe].dtypes \n",
    " \n",
    "\n",
    "Untuk konversi tipe data, secara default system akan mendeteksi data yang tidak bisa di render as date type or numeric type sebagai object yang basically string. Tidak bisa di render oleh system ini karena berbagai hal, mungkin karena formatnya asing dan tidak dikenali oleh python secara umum (misal: date type data → '2019Jan01').\n",
    "\n",
    "Data contoh tersebut tidak bisa di render karena bulannya Jan tidak bisa di translate menjadi in form of number (00-12) dan tidak ada ‘-’ di antara tahun, bulan dan harinya. Jika seluruh data pada kolom di order_date sudah tertulis dalam bentuk 'YYYY-MM-DD' maka ketika dibaca, kolom order_date sudah langsung dinyatakan bertipe data datetime.\n",
    "\n",
    "Untuk merubah kolom date_order yang sebelumnya bertipe object menjadi kolom bertipe datetime, cara pertama yang dapat dilakukan adalah menggunakan:\n",
    "\n",
    "pd.to_datetime(argumen) \n",
    "dengan argumen adalah isi kolom dari dataframe yang akan dirubah tipe datanya, misal dalam format umum.\n",
    "\n",
    "nama_dataframe[\"nama_kolom\"]\n",
    "Sehingga lengkapnya dapat ditulis sebagai:\n",
    "\n",
    "nama_dataframe[\"nama_kolom\"] = pd.to_datetime(nama_dataframe[\"nama_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming - Part 2\n",
    "Pada sub bab ini akan mengubah tipe data pada kolom dataframe yang telah dibaca menjadi tipe data float (kolom quantity) dan tipe kategori (kolom city).\n",
    "\n",
    "Secara umum, untuk mengubah ke numerik dapat menggunakan pd.to_numeric(), yaitu:\n",
    "\n",
    "nama_dataframe[\"nama_kolom\"] = pd.to_numeric(nama_dataframe[\"nama_kolom\"], downcast=\"tipe_data_baru\")\n",
    "Sedangkan untuk menjadi suatu kolom yang dapat dinyatakan sebagai kategori dapat menggunakan method .astype() pada dataframe, yaitu\n",
    "\n",
    "nama_dataframe[\"nama_kolom\"] = nama_dataframe[\"nama_kolom\"].astype("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming - Part 3\n",
    "Sekarang akan mempelajari teknik/cara berikutnya dalam proses transformasi suatu dataframe. Di sub bab ini akan memakai method .apply() dan .map() pada suatu dataframe.\n",
    "\n",
    " \n",
    "\n",
    "Method .apply() digunakan untuk menerapkan suatu fungsi python (yang dibuat dengan def atau anonymous dengan lambda) pada dataframe/series atau hanya kolom tertentu dari dataframe. \n",
    "\n",
    "Berikut ini adalah contohnya yaitu akan merubah setiap baris pada kolom brand menjadi lowercase.  \n",
    "\n",
    "\n",
    "Method .map() hanya dapat diterapkan pada series atau dataframe yang diakses satu kolom saja. Method ini digunakan untuk mensubstitusikan suatu nilai ke dalam tiap baris datanya.\n",
    "\n",
    "Mari lihat contoh yang diberikan berikut ini yang mana akan ambil huruf terakhir dari brand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Baca file sample_csv.csv\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_csv.csv\")\n",
    "# Cetak 5 baris teratas kolom brand\n",
    "print(\"Kolom brand awal:\\n\", df[\"brand\"].head())\n",
    "# Gunakan method apply untuk merubah isi kolom menjadi lower case\n",
    "df[\"brand\"] = df[\"brand\"].apply(lambda x: x.lower())\n",
    "# Cetak 5 baris teratas kolom brand\n",
    "print(\"Kolom brand setelah apply:\\n\", df[\"brand\"].head())\n",
    "# Gunakan method map untuk mengambil kode brand yaitu karakter terakhirnya\n",
    "df[\"brand\"] = df[\"brand\"].apply(lambda x: x[-1])\n",
    "# Cetak 5 baris teratas kolom brand\n",
    "print(\"Kolom brand setelah map:\\n\", df[\"brand\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming - Part 4\n",
    "Di sub bab sebelumnya sudah mengetahui bahwa map hanya dapat digunakan untuk pandas series. Pada sub bab ini akan menggunakan method .applymap pada dataframe.\n",
    "\n",
    " Cara 1 dengan tanpa define function awalnya, langsung pake fungsi anonymous lambda x\n",
    " \n",
    " \n",
    " Cara 2 dengan define function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe:\n",
      "           0         1         2         3\n",
      "0  0.191519  0.622109  0.437728  0.785359\n",
      "1  0.779976  0.272593  0.276464  0.801872\n",
      "2  0.958139  0.875933  0.357817  0.500995\n",
      "\n",
      "Dataframe - cara 1:\n",
      "           0         1         2         3\n",
      "0  2.611238  4.253346  3.504789  4.972864\n",
      "1  4.948290  2.892085  2.905825  5.048616\n",
      "2  5.792449  5.395056  3.201485  3.753981\n",
      "\n",
      "Dataframe - cara 2:\n",
      "           0         1         2         3\n",
      "0  2.611238  4.253346  3.504789  4.972864\n",
      "1  4.948290  2.892085  2.905825  5.048616\n",
      "2  5.792449  5.395056  3.201485  3.753981\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# number generator, set angka seed menjadi suatu angka, bisa semua angka, supaya hasil random nya selalu sama ketika kita run\n",
    "np.random.seed(1234)\n",
    "# create dataframe 3 baris dan 4 kolom dengan angka random\n",
    "df_tr = pd.DataFrame(np.random.rand(3,4)) \n",
    "# Cetak dataframe\n",
    "print(\"Dataframe:\\n\", df_tr)\n",
    "# Cara 1 dengan tanpa define function awalnya, langsung pake fungsi anonymous lambda x\n",
    "df_tr1 = df_tr.applymap(lambda x: x ** 2 + 3 * x + 2 ) \n",
    "print(\"\\nDataframe - cara 1:\\n\", df_tr1)\n",
    "# Cara 2 dengan define function \n",
    "def qudratic_fun(x):\n",
    "\treturn x ** 2 + 3 * x + 2\n",
    "df_tr2 = df_tr.applymap(qudratic_fun)\n",
    "print(\"\\nDataframe - cara 2:\\n\", df_tr2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "sample_csv = pd.read_csv('sample_csv.csv')\n",
    "\n",
    "sample_csv = sample_csv.set_index(['province','product_id'])\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "sample_csv.sort_index().loc[idx['Sulawesi Selatan', 'P3082':'P3357'], :]\n",
    "\n",
    "Code mana yang akan menghasilkan semua kolom, dengan filter province = ‘Sulawesi Selatan’ dan product_id dari ‘P3082’ sampai ‘P3357’?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treatment untuk Missing Value - Part 1\n",
    "Terdapat beberapa cara untuk mengatasi missing value, antara lain:\n",
    "\n",
    "- dibiarkan saja,\n",
    "- hapus value itu, atau\n",
    "- isi value tersebut dengan value yang lain (biasanya interpolasi, mean, median, etc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treatment untuk Missing Value - Part 2?\n",
    "\n",
    "__nama_dataframe.dropna(axis=1, how=\"all\")__\n",
    "\n",
    "Pada method .dropna() ada dua keyword argumen yang harus diisikan yaitu axis dan how. Keyword axis digunakan untuk menentukan arah dataframe yang akan dibuang angka 1 untuk menyatakan kolom (column-based) atau dapat ditulis dalam string \"column\". Jika digunakan angka 0 berarti itu dalam searah index (row-based) atau dapat ditulis dalam string \"index\".\n",
    "\n",
    "Sementara, keyword how digunakan untuk bagaimana cara membuangnya. Opsi yang dapat diterimanya (dalam string) adalah\n",
    "\n",
    "\"all\" artinya jika seluruh data di satu/beberapa kolom atau di satu/beberapa baris adalah missing value.\n",
    "\"any\" artinya jika memiliki 1 saja data yang hilang maka buanglah baris/kolom tersebut."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran awal df: 1000 baris, 13 kolom.\n",
      "Ukuran df setelah buang kolom dengan seluruh data missing: 1000 baris, 12 kolom.\n",
      "Ukuran df setelah dibuang baris yang memiliki sekurangnya 1 missing value: 746 baris, 12 kolom.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file \"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\"\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\")\n",
    "# Cetak ukuran awal dataframe\n",
    "print(\"Ukuran awal df: %d baris, %d kolom.\" % df.shape)\n",
    "# Drop kolom yang seluruhnya missing value dan cetak ukurannya\n",
    "df = df.dropna(axis=1, how='all')\n",
    "print(\"Ukuran df setelah buang kolom dengan seluruh data missing: %d baris, %d kolom.\" % df.shape)\n",
    "# Drop baris jika ada satu saja data yang missing dan cetak ukurannya\n",
    "df = df.dropna(axis=0, how='any')\n",
    "print(\"Ukuran df setelah dibuang baris yang memiliki sekurangnya 1 missing value: %d baris, %d kolom.\" % df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treatment untuk Missing Value - Part 3\n",
    "\n",
    "Sekarang, akan melakukan treatment ketiga untuk melakukan handle missing value pada dataframe. Treatment ini dilakukan dengan cara mengisi missing value dengan nilai lain, yang dapat berupa :\n",
    "\n",
    "- nilai statistik seperti mean atau median\n",
    "- interpolasi data\n",
    "- text tertentu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique value awal:\n",
      " [nan 'US' 'Guam' 'Iowa']\n",
      "Unique value setelah fillna:\n",
      " ['unknown_province_state' 'US' 'Guam' 'Iowa']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>province_state</th>\n",
       "      <th>country_region</th>\n",
       "      <th>date</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>location_geom</th>\n",
       "      <th>confirmed</th>\n",
       "      <th>deaths</th>\n",
       "      <th>recovered</th>\n",
       "      <th>active</th>\n",
       "      <th>fips</th>\n",
       "      <th>admin2</th>\n",
       "      <th>combined_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unknown_province_state</td>\n",
       "      <td>UK</td>\n",
       "      <td>01-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unknown_province_state</td>\n",
       "      <td>UK</td>\n",
       "      <td>18-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unknown_province_state</td>\n",
       "      <td>UK</td>\n",
       "      <td>17-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unknown_province_state</td>\n",
       "      <td>UK</td>\n",
       "      <td>31-01-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unknown_province_state</td>\n",
       "      <td>UK</td>\n",
       "      <td>19-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>unknown_province_state</td>\n",
       "      <td>UK</td>\n",
       "      <td>22-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unknown_province_state</td>\n",
       "      <td>UK</td>\n",
       "      <td>25-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>unknown_province_state</td>\n",
       "      <td>UK</td>\n",
       "      <td>16-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>unknown_province_state</td>\n",
       "      <td>UK</td>\n",
       "      <td>27-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>unknown_province_state</td>\n",
       "      <td>UK</td>\n",
       "      <td>03-02-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           province_state country_region      date  latitude  longitude  \\\n",
       "0  unknown_province_state             UK  01-02-20       NaN        NaN   \n",
       "1  unknown_province_state             UK  18-02-20       NaN        NaN   \n",
       "2  unknown_province_state             UK  17-02-20       NaN        NaN   \n",
       "3  unknown_province_state             UK  31-01-20       NaN        NaN   \n",
       "4  unknown_province_state             UK  19-02-20       NaN        NaN   \n",
       "5  unknown_province_state             UK  22-02-20       NaN        NaN   \n",
       "6  unknown_province_state             UK  25-02-20       NaN        NaN   \n",
       "7  unknown_province_state             UK  16-02-20       NaN        NaN   \n",
       "8  unknown_province_state             UK  27-02-20       NaN        NaN   \n",
       "9  unknown_province_state             UK  03-02-20       NaN        NaN   \n",
       "\n",
       "  location_geom  confirmed  deaths  recovered  active  fips admin2  \\\n",
       "0           NaN          2     0.0        0.0     NaN   NaN    NaN   \n",
       "1           NaN          9     0.0        8.0     NaN   NaN    NaN   \n",
       "2           NaN          9     0.0        8.0     NaN   NaN    NaN   \n",
       "3           NaN          2     NaN        NaN     NaN   NaN    NaN   \n",
       "4           NaN          9     0.0        8.0     NaN   NaN    NaN   \n",
       "5           NaN          9     0.0        8.0     NaN   NaN    NaN   \n",
       "6           NaN         13     0.0        8.0     NaN   NaN    NaN   \n",
       "7           NaN          9     0.0        8.0     NaN   NaN    NaN   \n",
       "8           NaN         15     0.0        8.0     NaN   NaN    NaN   \n",
       "9           NaN          2     0.0        0.0     NaN   NaN    NaN   \n",
       "\n",
       "   combined_key  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           NaN  \n",
       "5           NaN  \n",
       "6           NaN  \n",
       "7           NaN  \n",
       "8           NaN  \n",
       "9           NaN  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file \"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\"\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\")\n",
    "# Cetak unique value pada kolom province_state\n",
    "print(\"Unique value awal:\\n\", df['province_state'].unique())\n",
    "# Ganti missing value dengan string \"unknown_province_state\"\n",
    "df['province_state'] = df['province_state'].fillna('unknown_province_state')\n",
    "# Cetak kembali unique value pada kolom province_state\n",
    "print(\"Unique value setelah fillna:\\n\", df['province_state'].unique())\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treatment untuk Missing Value - Part 4\n",
    "\n",
    "Dalam sub bab ini akan mengganti missing value dengan nilai statistik kolom bersangkutan, baik median atau mean (nilai rata-rata). Misalnya akan menggunakan kolom active. Dengan mengabaikan terlebih dahulu sebaran berdasarkan negara (univariate), jika mengisi dengan nilai rata-rata maka harus melihat terlebih dahulu data apakah memiliki outliers atau tidak. Jika ada outliers dari data maka menggunakan nilai tengah (median) data adalah cara yang lebih safe.\n",
    "\n",
    "Untuk itu diputuskan dengan mengecek nilai median dan nilai mean kolom active juga nilai min dan max-nya. __Jika data pada kolom active terdistribusi normal maka nilai mean dan median akan hampir sama.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awal: mean = 192.571128, median = 41.000000.\n",
      "Fillna median: mean = 184.841000, median = 41.000000.\n",
      "Fillna mean: mean = 192.571128, median = 49.000000.\n",
      "0      41.0\n",
      "1      41.0\n",
      "2      41.0\n",
      "3      41.0\n",
      "4      41.0\n",
      "       ... \n",
      "995     9.0\n",
      "996    39.0\n",
      "997     4.0\n",
      "998    44.0\n",
      "999    13.0\n",
      "Name: active, Length: 1000, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file \"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\"\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/datacovid19.csv\")\n",
    "# Cetak nilai mean dan median awal \n",
    "print(\"Awal: mean = %f, median = %f.\" % (df[\"active\"].mean(), df['active'].median()))\n",
    "# Isi missing value kolom active dengan median\n",
    "df_median = df[\"active\"].fillna(df['active'].median())\n",
    "# Cetak nilai mean dan median awal setelah diisi dengan median\n",
    "print(\"Fillna median: mean = %f, median = %f.\" % (df_median.mean(), df_median.median()))\n",
    "# Isi missing value kolom active dengan mean\n",
    "df_mean = df[\"active\"].fillna(df['active'].mean())\n",
    "# Cetak nilai mean dan median awal setelah diisi dengan mean\n",
    "print(\"Fillna mean: mean = %f, median = %f.\" % (df_mean.mean(), df_mean.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treatment untuk Missing Value - Part 5\n",
    "Di bagian ini akan menggunakan teknik interpolasi dalam mengisi nilai missing value pada suatu dataset.\n",
    "\n",
    "Data yang menggunakan interpolasi untuk mengisi data yang hilang adalah time series data, yang secara default akan diisi dengan interpolasi linear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setelah diisi missing valuenya:\n",
      " 2020-01-01     9.0\n",
      "2020-01-02    14.0\n",
      "2020-01-05    19.0\n",
      "2020-01-07    24.0\n",
      "2020-01-10    27.0\n",
      "2020-01-12    30.0\n",
      "2020-01-15    33.0\n",
      "2020-01-17    36.5\n",
      "2020-01-16    40.0\n",
      "2020-01-20    45.0\n",
      "2020-01-22    52.0\n",
      "2020-01-25    75.0\n",
      "2020-01-28    75.0\n",
      "2020-01-30    75.0\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# Data\n",
    "ts = pd.Series({\n",
    "   \"2020-01-01\":9,\n",
    "   \"2020-01-02\":np.nan,\n",
    "   \"2020-01-05\":np.nan,\n",
    "   \"2020-01-07\":24,\n",
    "   \"2020-01-10\":np.nan,\n",
    "   \"2020-01-12\":np.nan,\n",
    "   \"2020-01-15\":33,\n",
    "   \"2020-01-17\":np.nan,\n",
    "   \"2020-01-16\":40,\n",
    "   \"2020-01-20\":45,\n",
    "   \"2020-01-22\":52,\n",
    "   \"2020-01-25\":75,\n",
    "   \"2020-01-28\":np.nan,\n",
    "   \"2020-01-30\":np.nan\n",
    "})\n",
    "# Isi missing value menggunakan interpolasi linier\n",
    "ts = ts.interpolate()\n",
    "# Cetak time series setelah interpolasi linier\n",
    "print(\"Setelah diisi missing valuenya:\\n\", ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] BACA DATASET\n",
      "    Dataset:\n",
      "    order_id    order_date customer_id           city     province    brand  \\\n",
      "0   1730350  Dec 11, 2019      '13447      Surakarta  Jawa Tengah  BRAND_F   \n",
      "1   1677490  Jul 31, 2019          '0            NaN          NaN  BRAND_F   \n",
      "2   1704211  Oct 18, 2019      '16128  Jakarta Pusat  DKI Jakarta  BRAND_H   \n",
      "3   1679695  Aug 07, 2019      '16225     Yogyakarta   Yogyakarta  BRAND_H   \n",
      "4   1679080  Aug 05, 2019          '0            NaN          NaN  BRAND_E   \n",
      "\n",
      "  quantity item_price  product_value  \n",
      "0      '24    '113000         1374.0  \n",
      "1       '1   '1164000         1370.0  \n",
      "2      '12    '747000         1679.0  \n",
      "3       '6    '590000         1708.0  \n",
      "4       '2    '740000         1201.0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   order_id       5000 non-null   int64  \n",
      " 1   order_date     5000 non-null   object \n",
      " 2   customer_id    5000 non-null   object \n",
      " 3   city           3802 non-null   object \n",
      " 4   province       3802 non-null   object \n",
      " 5   brand          4995 non-null   object \n",
      " 6   quantity       5000 non-null   object \n",
      " 7   item_price     5000 non-null   object \n",
      " 8   product_value  4995 non-null   float64\n",
      "dtypes: float64(1), int64(1), object(7)\n",
      "memory usage: 351.7+ KB\n",
      "    Info:\n",
      " None\n",
      "\n",
      "[2] UBAH TIPE DATA\n",
      "    Tipe data:\n",
      " order_id           int64\n",
      "order_date        object\n",
      "customer_id        int64\n",
      "city              object\n",
      "province          object\n",
      "brand             object\n",
      "quantity           int64\n",
      "item_price         int64\n",
      "product_value    float64\n",
      "dtype: object\n",
      "\n",
      "[3] TRANSFORM product_value MENJADI product_id\n",
      "   order_id    order_date  customer_id           city     province    brand  \\\n",
      "0   1730350  Dec 11, 2019        13447      Surakarta  Jawa Tengah  BRAND_F   \n",
      "1   1677490  Jul 31, 2019            0            NaN          NaN  BRAND_F   \n",
      "2   1704211  Oct 18, 2019        16128  Jakarta Pusat  DKI Jakarta  BRAND_H   \n",
      "3   1679695  Aug 07, 2019        16225     Yogyakarta   Yogyakarta  BRAND_H   \n",
      "4   1679080  Aug 05, 2019            0            NaN          NaN  BRAND_E   \n",
      "\n",
      "   quantity  item_price product_id  \n",
      "0        24      113000      P1374  \n",
      "1         1     1164000      P1370  \n",
      "2        12      747000      P1679  \n",
      "3         6      590000      P1708  \n",
      "4         2      740000      P1201  \n",
      "\n",
      "[4] TRANSFORM order_date MENJADI FORMAT YYYY-mm-dd\n",
      "    Tipe data:\n",
      " order_id                int64\n",
      "order_date     datetime64[ns]\n",
      "customer_id             int64\n",
      "city                   object\n",
      "province               object\n",
      "brand                  object\n",
      "quantity                int64\n",
      "item_price              int64\n",
      "product_id             object\n",
      "dtype: object\n",
      "\n",
      "[5] HANDLING MISSING VALUE\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Non-Null Count  Dtype         \n",
      "---  ------       --------------  -----         \n",
      " 0   order_id     5000 non-null   int64         \n",
      " 1   order_date   5000 non-null   datetime64[ns]\n",
      " 2   customer_id  5000 non-null   int64         \n",
      " 3   city         5000 non-null   object        \n",
      " 4   province     5000 non-null   object        \n",
      " 5   brand        5000 non-null   object        \n",
      " 6   quantity     5000 non-null   int64         \n",
      " 7   item_price   5000 non-null   int64         \n",
      " 8   product_id   5000 non-null   object        \n",
      "dtypes: datetime64[ns](1), int64(4), object(4)\n",
      "memory usage: 351.7+ KB\n",
      "    Info:\n",
      " None\n",
      "\n",
      "[6] MEMBUAT KOLOM BARU city/province\n",
      "   order_id order_date  customer_id    brand  quantity  item_price product_id  \\\n",
      "0   1730350 2019-12-11        13447  BRAND_F        24      113000      P1374   \n",
      "1   1677490 2019-07-31            0  BRAND_F         1     1164000      P1370   \n",
      "2   1704211 2019-10-18        16128  BRAND_H        12      747000      P1679   \n",
      "3   1679695 2019-08-07        16225  BRAND_H         6      590000      P1708   \n",
      "4   1679080 2019-08-05            0  BRAND_E         2      740000      P1201   \n",
      "\n",
      "               city/province  \n",
      "0      Surakarta/Jawa Tengah  \n",
      "1            unknown/unknown  \n",
      "2  Jakarta Pusat/DKI Jakarta  \n",
      "3      Yogyakarta/Yogyakarta  \n",
      "4            unknown/unknown  \n",
      "\n",
      "[7] MEMBUAT HIERACHICAL INDEX\n",
      "                                                                     brand  \\\n",
      "city/province          order_date customer_id order_id product_id            \n",
      "Banda Aceh/Aceh        2019-04-17 12818       1642480  P1936       BRAND_K   \n",
      "                       2019-11-12 12360       1715116  P0758       BRAND_C   \n",
      "                                                       P3042       BRAND_R   \n",
      "                       2019-12-09 12374       1729036  P1660       BRAND_G   \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628       BRAND_C   \n",
      "\n",
      "                                                                   quantity  \\\n",
      "city/province          order_date customer_id order_id product_id             \n",
      "Banda Aceh/Aceh        2019-04-17 12818       1642480  P1936             24   \n",
      "                       2019-11-12 12360       1715116  P0758              8   \n",
      "                                                       P3042             12   \n",
      "                       2019-12-09 12374       1729036  P1660              4   \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628             12   \n",
      "\n",
      "                                                                   item_price  \n",
      "city/province          order_date customer_id order_id product_id              \n",
      "Banda Aceh/Aceh        2019-04-17 12818       1642480  P1936           450000  \n",
      "                       2019-11-12 12360       1715116  P0758           695000  \n",
      "                                                       P3042           310000  \n",
      "                       2019-12-09 12374       1729036  P1660          2795000  \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628           695000  \n",
      "\n",
      "[8] MEMBUAT KOLOM total_price\n",
      "                                                                     brand  \\\n",
      "city/province          order_date customer_id order_id product_id            \n",
      "Banda Aceh/Aceh        2019-04-17 12818       1642480  P1936       BRAND_K   \n",
      "                       2019-11-12 12360       1715116  P0758       BRAND_C   \n",
      "                                                       P3042       BRAND_R   \n",
      "                       2019-12-09 12374       1729036  P1660       BRAND_G   \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628       BRAND_C   \n",
      "\n",
      "                                                                   quantity  \\\n",
      "city/province          order_date customer_id order_id product_id             \n",
      "Banda Aceh/Aceh        2019-04-17 12818       1642480  P1936             24   \n",
      "                       2019-11-12 12360       1715116  P0758              8   \n",
      "                                                       P3042             12   \n",
      "                       2019-12-09 12374       1729036  P1660              4   \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628             12   \n",
      "\n",
      "                                                                   item_price  \\\n",
      "city/province          order_date customer_id order_id product_id               \n",
      "Banda Aceh/Aceh        2019-04-17 12818       1642480  P1936           450000   \n",
      "                       2019-11-12 12360       1715116  P0758           695000   \n",
      "                                                       P3042           310000   \n",
      "                       2019-12-09 12374       1729036  P1660          2795000   \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628           695000   \n",
      "\n",
      "                                                                   total_price  \n",
      "city/province          order_date customer_id order_id product_id               \n",
      "Banda Aceh/Aceh        2019-04-17 12818       1642480  P1936          10800000  \n",
      "                       2019-11-12 12360       1715116  P0758           5560000  \n",
      "                                                       P3042           3720000  \n",
      "                       2019-12-09 12374       1729036  P1660          11180000  \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628           8340000  \n",
      "\n",
      "[9] SLICE DATASET UNTUK BULAN JANUARI 2019 SAJA\n",
      "Dataset akhir:\n",
      "                                                                      brand  \\\n",
      "city/province          order_date customer_id order_id product_id            \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628       BRAND_C   \n",
      "Bandung/Jawa Barat     2019-01-09 16134       1617055  P1597       BRAND_G   \n",
      "                       2019-01-10 17392       1617952  P2137       BRAND_M   \n",
      "                       2019-01-14 15527       1618828  P3115       BRAND_S   \n",
      "                       2019-01-29 13253       1620289  P0099       BRAND_A   \n",
      "...                                                                    ...   \n",
      "unknown/unknown        2019-01-30 0           1620766  P3070       BRAND_R   \n",
      "                                                       P3483       BRAND_S   \n",
      "                       2019-01-31 0           1621057  P1298       BRAND_F   \n",
      "                                                       P1773       BRAND_H   \n",
      "                                                       P2877       BRAND_R   \n",
      "\n",
      "                                                                   quantity  \\\n",
      "city/province          order_date customer_id order_id product_id             \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628             12   \n",
      "Bandung/Jawa Barat     2019-01-09 16134       1617055  P1597              9   \n",
      "                       2019-01-10 17392       1617952  P2137              2   \n",
      "                       2019-01-14 15527       1618828  P3115              1   \n",
      "                       2019-01-29 13253       1620289  P0099             12   \n",
      "...                                                                     ...   \n",
      "unknown/unknown        2019-01-30 0           1620766  P3070              1   \n",
      "                                                       P3483              3   \n",
      "                       2019-01-31 0           1621057  P1298              1   \n",
      "                                                       P1773              5   \n",
      "                                                       P2877              1   \n",
      "\n",
      "                                                                   item_price  \\\n",
      "city/province          order_date customer_id order_id product_id               \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628           695000   \n",
      "Bandung/Jawa Barat     2019-01-09 16134       1617055  P1597           520000   \n",
      "                       2019-01-10 17392       1617952  P2137          1062000   \n",
      "                       2019-01-14 15527       1618828  P3115          1045000   \n",
      "                       2019-01-29 13253       1620289  P0099           450000   \n",
      "...                                                                       ...   \n",
      "unknown/unknown        2019-01-30 0           1620766  P3070           593000   \n",
      "                                                       P3483           593000   \n",
      "                       2019-01-31 0           1621057  P1298           296000   \n",
      "                                                       P1773           593000   \n",
      "                                                       P2877          1486000   \n",
      "\n",
      "                                                                   total_price  \n",
      "city/province          order_date customer_id order_id product_id               \n",
      "Bandar Lampung/Lampung 2019-01-15 12515       1619257  P0628           8340000  \n",
      "Bandung/Jawa Barat     2019-01-09 16134       1617055  P1597           4680000  \n",
      "                       2019-01-10 17392       1617952  P2137           2124000  \n",
      "                       2019-01-14 15527       1618828  P3115           1045000  \n",
      "                       2019-01-29 13253       1620289  P0099           5400000  \n",
      "...                                                                        ...  \n",
      "unknown/unknown        2019-01-30 0           1620766  P3070            593000  \n",
      "                                                       P3483           1779000  \n",
      "                       2019-01-31 0           1621057  P1298            296000  \n",
      "                                                       P1773           2965000  \n",
      "                                                       P2877           1486000  \n",
      "\n",
      "[334 rows x 4 columns]\n",
      "city/province            object\n",
      "order_date       datetime64[ns]\n",
      "customer_id               int64\n",
      "order_id                  int64\n",
      "product_id               object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1. Baca dataset\n",
    "print(\"[1] BACA DATASET\")\n",
    "df = pd.read_csv('https://storage.googleapis.com/dqlab-dataset/retail_raw_test.csv', low_memory=False)\n",
    "print(\"    Dataset:\\n\", df.head(5))\n",
    "print(\"    Info:\\n\", df.info())\n",
    "\n",
    "# 2. Ubah tipe data\n",
    "print(\"\\n[2] UBAH TIPE DATA\")\n",
    "df[\"customer_id\"] = df[\"customer_id\"].apply(lambda x : x.split(\"'\")[1]).astype(\"int64\")\n",
    "df['quantity'] = df['quantity'].apply(lambda x : x.split(\"'\")[1]).astype('int64')\n",
    "df[\"item_price\"] = df['item_price'].apply(lambda x : x.split(\"'\")[1]).astype('int64')\n",
    "print(\"    Tipe data:\\n\", df.dtypes)\n",
    "\n",
    "# 3. Transform \"product_value\" supaya bentuknya seragam dengan format \"PXXXX\", assign ke kolom baru \"product_id\", dan drop kolom \"product_value\", jika terdapat nan gantilah dengan \"unknown\"\n",
    "print(\"\\n[3] TRANSFORM product_value MENJADI product_id\")\n",
    "# Buat fungsi\n",
    "import math\n",
    "def impute_product_value(val):\n",
    "    if math.isnan(val):\n",
    "        return 'unknown'\n",
    "    else:\n",
    "        return 'P' + '{:0>4}'.format(str(val).split('.')[0])\n",
    "# df['product_value'].fillna('unknown')\n",
    "# df['product_id']= df['product_value'].apply(lambda x : f\"P{str(x).split('.')[0]}\")\n",
    "# Buat kolom \"product_id\"\n",
    "df[\"product_id\"] = df['product_value'].apply(lambda x: impute_product_value(x))\n",
    "# Hapus kolom \"product_value\"\n",
    "df.drop(['product_value'], axis=1, inplace=True)\n",
    "# Cetak 5 data teratas\n",
    "print(df.head())\n",
    "\n",
    "# 4. Tranform order_date menjadi value dengan format \"YYYY-mm-dd\"\n",
    "print(\"\\n[4] TRANSFORM order_date MENJADI FORMAT YYYY-mm-dd\")\n",
    "months_dict = {\n",
    "   \"Jan\":\"01\",\n",
    "   \"Feb\":\"02\",\n",
    "   \"Mar\":\"03\",\n",
    "   \"Apr\":\"04\",\n",
    "   \"May\":\"05\",\n",
    "   \"Jun\":\"06\",\n",
    "   \"Jul\":\"07\",\n",
    "   \"Aug\":\"08\",\n",
    "   \"Sep\":\"09\",\n",
    "   \"Oct\":\"10\",\n",
    "   \"Nov\":\"11\",\n",
    "   \"Dec\":\"12\"\n",
    "}\n",
    "# df['order_date'] = pd.to_datetime(df['order_date'].apply(lambda x: str(x)[-4:] + '-' + months_dict[str(x)[:3]] + '-' + str(x)[4:6]))\n",
    "df[\"order_date\"] = pd.to_datetime(df['order_date'].apply(lambda x : str(x)[-4:] + \"-\" + months_dict[str(x)[:3]] + \"-\" + str(x)[4:7]))                                                     \n",
    "print(\"    Tipe data:\\n\", df.dtypes)\n",
    "\n",
    "# 5. Mengatasi data yang hilang di beberapa kolom\n",
    "print(\"\\n[5] HANDLING MISSING VALUE\")\n",
    "# Kolom \"city\" dan \"province\" masih memiliki missing value, nilai yang hilang di kedua kolom ini diisi saja dengan \"unknown\"\n",
    "df[[\"city\",'province']] = df[['city','province']].fillna('unknown')\n",
    "# Kolom brand juga masih memiliki missing value, Ganti value NaN menjadi \"no_brand\"\n",
    "df[\"brand\"] = df['brand'].fillna('no_brand')\n",
    "# Cek apakah masih terdapat missing value di seluruh kolom \n",
    "print(\"    Info:\\n\", df.info())\n",
    "\n",
    "# 6. Membuat kolom baru \"city/province\" dengan menggabungkan kolom \"city\" dan kolom \"province\" dan delete kolom asalnya\n",
    "print(\"\\n[6] MEMBUAT KOLOM BARU city/province\")\n",
    "df[\"city/province\"] = df[\"city\"] + \"/\" + df['province']\n",
    "# drop kolom \"city\" dan \"province\" karena telah digabungkan\n",
    "df.drop(['city','province'], axis=1, inplace=True)\n",
    "# Cetak 5 data teratas\n",
    "print(df.head())\n",
    "\n",
    "# 7. Membuat hierarchical index yang terdiri dari kolom \"city/province\", \"order_date\", \"customer_id\", \"order_id\", \"product_id\"\n",
    "print(\"\\n[7] MEMBUAT HIERACHICAL INDEX\")\n",
    "df = df.set_index(['city/province','order_date','customer_id','order_id','product_id'])\n",
    "# urutkanlah berdasarkan index yang baru\n",
    "df = df.sort_index()\n",
    "# Cetak 5 data teratas\n",
    "print(df.head())\n",
    "\n",
    "# 8. Membuat kolom \"total_price\" yang formula nya perkalian antara kolom \"quantity\" dan kolom \"item_price\"\n",
    "print(\"\\n[8] MEMBUAT KOLOM total_price\")\n",
    "df[\"total_price\"] = df['quantity'] * df[\"item_price\"]\n",
    "# Cetak 5 data teratas\n",
    "print(df.head())\n",
    "\n",
    "# 9. Slice dataset agar hanya terdapat data bulan Januari 2019\n",
    "print(\"\\n[9] SLICE DATASET UNTUK BULAN JANUARI 2019 SAJA\")\n",
    "idx = pd.IndexSlice\n",
    "df_jan2019 = df.loc[idx[:, \"2019-01-01\":\"2019-01-31\"], :]\n",
    "print(\"Dataset akhir:\\n\", df_jan2019)\n",
    "print(df.index.dtypes)\n",
    "\n",
    "# END OF PROJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ser = pd.Series(np.sort(np.random.uniform(size=100)))\n",
    "new_index = ser.index.union(pd.Index([49.25, 49.5, 49.75, 50.25, 50.5, 50.75]))\n",
    "interp_s = ser.reindex(new_index).interpolate(method='pchip')\n",
    "interp_s.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_date : 2019-01-01\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>city</th>\n",
       "      <th>province</th>\n",
       "      <th>product_id</th>\n",
       "      <th>brand</th>\n",
       "      <th>quantity</th>\n",
       "      <th>item_price</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order_date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>1612339</td>\n",
       "      <td>18055</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>DKI Jakarta</td>\n",
       "      <td>P0648</td>\n",
       "      <td>BRAND_C</td>\n",
       "      <td>4</td>\n",
       "      <td>1934000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>1612339</td>\n",
       "      <td>18055</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>DKI Jakarta</td>\n",
       "      <td>P3826</td>\n",
       "      <td>BRAND_V</td>\n",
       "      <td>8</td>\n",
       "      <td>604000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>1612339</td>\n",
       "      <td>18055</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>DKI Jakarta</td>\n",
       "      <td>P1508</td>\n",
       "      <td>BRAND_G</td>\n",
       "      <td>12</td>\n",
       "      <td>747000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>1612339</td>\n",
       "      <td>18055</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>DKI Jakarta</td>\n",
       "      <td>P0520</td>\n",
       "      <td>BRAND_B</td>\n",
       "      <td>12</td>\n",
       "      <td>450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>1612339</td>\n",
       "      <td>18055</td>\n",
       "      <td>Jakarta Selatan</td>\n",
       "      <td>DKI Jakarta</td>\n",
       "      <td>P1513</td>\n",
       "      <td>BRAND_G</td>\n",
       "      <td>3</td>\n",
       "      <td>1500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>1612390</td>\n",
       "      <td>12681</td>\n",
       "      <td>Makassar</td>\n",
       "      <td>Sulawesi Selatan</td>\n",
       "      <td>P3388</td>\n",
       "      <td>BRAND_S</td>\n",
       "      <td>10</td>\n",
       "      <td>450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>1612390</td>\n",
       "      <td>12681</td>\n",
       "      <td>Makassar</td>\n",
       "      <td>Sulawesi Selatan</td>\n",
       "      <td>P3082</td>\n",
       "      <td>BRAND_R</td>\n",
       "      <td>18</td>\n",
       "      <td>1045000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>1612390</td>\n",
       "      <td>12681</td>\n",
       "      <td>Makassar</td>\n",
       "      <td>Sulawesi Selatan</td>\n",
       "      <td>P3354</td>\n",
       "      <td>BRAND_S</td>\n",
       "      <td>24</td>\n",
       "      <td>450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>1612390</td>\n",
       "      <td>12681</td>\n",
       "      <td>Makassar</td>\n",
       "      <td>Sulawesi Selatan</td>\n",
       "      <td>P3357</td>\n",
       "      <td>BRAND_S</td>\n",
       "      <td>24</td>\n",
       "      <td>450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-01</th>\n",
       "      <td>1612390</td>\n",
       "      <td>12681</td>\n",
       "      <td>Makassar</td>\n",
       "      <td>Sulawesi Selatan</td>\n",
       "      <td>P0422</td>\n",
       "      <td>BRAND_B</td>\n",
       "      <td>4</td>\n",
       "      <td>1325000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            order_id  customer_id             city          province  \\\n",
       "order_date                                                             \n",
       "2019-01-01   1612339        18055  Jakarta Selatan       DKI Jakarta   \n",
       "2019-01-01   1612339        18055  Jakarta Selatan       DKI Jakarta   \n",
       "2019-01-01   1612339        18055  Jakarta Selatan       DKI Jakarta   \n",
       "2019-01-01   1612339        18055  Jakarta Selatan       DKI Jakarta   \n",
       "2019-01-01   1612339        18055  Jakarta Selatan       DKI Jakarta   \n",
       "...              ...          ...              ...               ...   \n",
       "2019-01-01   1612390        12681         Makassar  Sulawesi Selatan   \n",
       "2019-01-01   1612390        12681         Makassar  Sulawesi Selatan   \n",
       "2019-01-01   1612390        12681         Makassar  Sulawesi Selatan   \n",
       "2019-01-01   1612390        12681         Makassar  Sulawesi Selatan   \n",
       "2019-01-01   1612390        12681         Makassar  Sulawesi Selatan   \n",
       "\n",
       "           product_id    brand  quantity  item_price  \n",
       "order_date                                            \n",
       "2019-01-01      P0648  BRAND_C         4     1934000  \n",
       "2019-01-01      P3826  BRAND_V         8      604000  \n",
       "2019-01-01      P1508  BRAND_G        12      747000  \n",
       "2019-01-01      P0520  BRAND_B        12      450000  \n",
       "2019-01-01      P1513  BRAND_G         3     1500000  \n",
       "...               ...      ...       ...         ...  \n",
       "2019-01-01      P3388  BRAND_S        10      450000  \n",
       "2019-01-01      P3082  BRAND_R        18     1045000  \n",
       "2019-01-01      P3354  BRAND_S        24      450000  \n",
       "2019-01-01      P3357  BRAND_S        24      450000  \n",
       "2019-01-01      P0422  BRAND_B         4     1325000  \n",
       "\n",
       "[101 rows x 8 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file TSV sample_tsv.tsv\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_tsv.tsv\", sep=\"\\t\")\n",
    "# Set multi index df\n",
    "df_x = df.set_index('order_date', 'city', 'customer_id'])\n",
    "# Print nama dan level dari multi index\n",
    "for name, level in zip(df_x.index.names, df_x.index):\n",
    "    print(name,':',level)\n",
    "    \n",
    "df_x"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
