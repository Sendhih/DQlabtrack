{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memanggil Library Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame & Series\n",
    "\n",
    "Di Pandas terdapat 2 kelas data baru yang digunakan sebagai struktur dari spreadsheet:\n",
    "\n",
    "Series: satu kolom bagian dari tabel dataframe yang merupakan 1 dimensional numpy array sebagai basis datanya, terdiri dari 1 tipe data (integer, string, float, dll).\n",
    "DataFrame: gabungan dari Series, berbentuk rectangular data yang merupakan tabel spreadsheet itu sendiri (karena dibentuk dari banyak Series, tiap Series biasanya punya 1 tipe data, yang artinya 1 dataframe bisa memiliki banyak tipe data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series:\n",
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "5    6\n",
      "dtype: int64\n",
      "DataFrame:\n",
      "   0  1  2\n",
      "0  1  2  3\n",
      "1  a  b  c\n",
      "2  3  4  5\n",
      "3  d  4  6\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Series\n",
    "number_list = pd.Series([1,2,3,4,5,6])\n",
    "print(\"Series:\")\n",
    "print(number_list)\n",
    "# DataFrame\n",
    "matrix = [[1,2,3],\n",
    "          ['a', 'b', 'c'],\n",
    "          [3,4,5],\n",
    "          ['d', 4, 6]]\n",
    "matrix_list = pd.DataFrame(matrix)\n",
    "print(\"DataFrame:\")\n",
    "print(matrix_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atribut DataFrame & Series - Part 1\n",
    "\n",
    "Method Python in pandas\n",
    "\n",
    "1. Method .info()\n",
    "\n",
    "Method .info() digunakan untuk mengecek kolom apa yang membentuk dataframe itu, data types, berapa yang non null, dll. Method ini tidak dapat digunakan pada series, hanya pada dataframe saja.\n",
    "\n",
    "![](images/34.png)\n",
    "\n",
    "Output di console untuk penggunaan method .info() ini adalah:\n",
    "\n",
    "![](images/35.png)\n",
    "\n",
    "2. Attribute .shape\n",
    "\n",
    "Attribute .shape digunakan untuk mengetahui berapa baris dan kolom, hasilnya dalam format tuple (baris, kolom).\n",
    "\n",
    "![](images/36.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .shape ini adalah:\n",
    "\n",
    "![](images/37.png)\n",
    "\n",
    "3. Attribute .dtypes\n",
    "\n",
    "Attribute .dtypes digunakan untuk mengetahui tipe data di tiap kolom. Tipe data object: kombinasi untuk berbagai tipe data (number & text, etc).\n",
    "\n",
    "![](images/38.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .dtypes ini adalah:\n",
    "\n",
    "![](images/39.png)\n",
    "\n",
    "4. Method .astype(nama_tipe_data)\n",
    "\n",
    "Method .astype(nama_tipe_data) untuk convert tipe data berdasarkan tipe data seperti: float, int, str, numpy.float, numpy.int ataupun numpy.datetime.\n",
    "\n",
    "![](images/40.png)\n",
    "\n",
    "Output di console untuk penggunaan method .astype() ini adalah:\n",
    "\n",
    "![](images/41.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Series\n",
    "number_list = pd.Series([1,2,3,4,5,6])\n",
    "# DataFrame\n",
    "matrix_list = pd.DataFrame([[1,2,3],\n",
    "\t\t\t\t            ['a','b','c'],\n",
    "\t\t\t\t            [3,4,5],\n",
    "\t\t\t\t            ['d',4,6]])\n",
    "# [1] method .info()\n",
    "print(\"[1] method .info()\")\n",
    "print(matrix_list.info())\n",
    "# [2] attribute .shape\n",
    "print(\"\\n[2] attribute .shape\")\n",
    "print(\"    Shape dari number_list:\", number_list.shape)\n",
    "print(\"    Shape dari matrix_list:\", matrix_list.shape)\n",
    "# [3] attribute .dtypes\n",
    "print(\"\\n[3] attribute .dtypes\")\n",
    "print(\"    Tipe data number_list:\", number_list.dtypes)\n",
    "print(\"    Tipe data matrix_list:\", matrix_list.dtypes)\n",
    "# [4] attribute .astype()\n",
    "print(\"\\n[4] method .astype()\")\n",
    "print(\"    Konversi number_list ke str:\", number_list.astype(\"str\"))\n",
    "print(\"    Konversi matrix_list ke str:\", matrix_list.astype(\"str\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atribut DataFrame & Series - Part 2\n",
    "\n",
    "5. Attribute .copy()\n",
    "\n",
    "Attribute .copy() digunakan melakukan duplikat, untuk disimpan di variable yang berbeda mungkin supaya tidak loading data lagi.\n",
    "\n",
    "![](images/42.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .copy() ini adalah:\n",
    "\n",
    "![](images/43.png)\n",
    "\n",
    "6. Attribute .to_list()\n",
    "\n",
    "Attribute .to_list() digunakan untuk mengubah series menjadi list dan tidak dapat digunakan untuk dataframe.\n",
    "\n",
    "![](images/44.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .to_list() ini adalah:\n",
    "\n",
    "![](images/45.png)\n",
    "\n",
    "7. Attribute .unique()\n",
    "\n",
    "Attribute .unique() digunakan menghasilkan nilai unik dari suatu kolom, hasilnya dalam bentuk numpy array. Attribute ini hanya digunakan pada series saja.\n",
    "\n",
    "![](images/46.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .unique() ini adalah:\n",
    "\n",
    "![](images/47.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Series\n",
    "number_list = pd.Series([1,2,3,4,5,6])\n",
    "# DataFrame\n",
    "matrix_list = pd.DataFrame([[1,2,3],\n",
    "\t\t\t\t            ['a','b','c'],\n",
    "\t\t\t\t            [3,4,5],\n",
    "\t\t\t\t            ['d',4,6]])\n",
    "# [5] attribute .copy()\n",
    "print(\"[5] attribute .copy()\")\n",
    "num_list = number_list.copy()\n",
    "print(\"    Copy number_list ke num_list:\", num_list)\n",
    "mtr_list = matrix_list.copy()\n",
    "print(\"    Copy matrix_list ke mtr_list:\", mtr_list)\t\n",
    "# [6] attribute .to_list()\n",
    "print(\"[6] attribute .to_list()\")\n",
    "print(number_list.to_list())\n",
    "# [7] attribute .unique()\n",
    "print(\"[7] attribute .unique()\")\n",
    "print(number_list.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Atribut DataFrame & Series - Part 3\n",
    "\n",
    "8. Attribute .index\n",
    "\n",
    "Attribute .index digunakan untuk mencari index/key dari Series atau Dataframe.\n",
    "\n",
    "![](images/48.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .index ini adalah:\n",
    "\n",
    "![](images/49.png)\n",
    "\n",
    "9. Attribute .columns\n",
    "\n",
    "Attribute .columns digunakan untuk mengetahui apa saja kolom yang tersedia di dataframe tersebut (hanya digunakan untuk dataframe saja). \n",
    "\n",
    "![](images/50.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .columns ini adalah:\n",
    "\n",
    "![](images/51.png)\n",
    "\n",
    "10. Attribute .loc\n",
    "\n",
    "Attribute .loc digunakan slice dataframe atau series berdasarkan nama kolom dan/atau nama index.\n",
    "\n",
    "![](images/52.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .loc[] ini adalah:\n",
    "\n",
    "![](images/53.png)\n",
    "\n",
    "11. Attribute .iloc\n",
    "\n",
    "Attribute .iloc digunakan untuk slice dataframe atau series berdasarkan index kolom dan/atau index.\n",
    "\n",
    "![](images/54.png)\n",
    "\n",
    "Output di console untuk penggunaan attribute .iloc[] ini adalah:\n",
    "\n",
    "![](images/55.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8] attribute .index\n",
      "    Index number_list: RangeIndex(start=0, stop=6, step=1)\n",
      "    Index matrix_list: RangeIndex(start=0, stop=4, step=1)\n",
      "[9] attribute .columns\n",
      "    Column matrix_list: RangeIndex(start=0, stop=3, step=1)\n",
      "[10] attribute .loc\n",
      "    .loc[0:1] pada number_list: 0    1\n",
      "1    2\n",
      "dtype: int64\n",
      "    .loc[0:1] pada matrix_list:    0  1  2\n",
      "0  1  2  3\n",
      "1  a  b  c\n",
      "[11] attribute .iloc\n",
      "    iloc[0:1] pada number_list: 0    1\n",
      "dtype: int64\n",
      "    iloc[0:1] pada matrix_list:    0  1  2\n",
      "0  1  2  3\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Series\n",
    "number_list = pd.Series([1,2,3,4,5,6])\n",
    "# DataFrame\n",
    "matrix_list = pd.DataFrame([[1,2,3],\n",
    "\t\t\t\t            ['a','b','c'],\n",
    "\t\t\t\t            [3,4,5],\n",
    "\t\t\t\t            ['d',4,6]])\n",
    "# [8] attribute .index\n",
    "print(\"[8] attribute .index\")\n",
    "print(\"    Index number_list:\", number_list.index)\n",
    "print(\"    Index matrix_list:\", matrix_list.index)\t\n",
    "# [9] attribute .columns\n",
    "print(\"[9] attribute .columns\")\n",
    "print(\"    Column matrix_list:\", matrix_list.columns)\n",
    "# [10] attribute .loc\n",
    "print(\"[10] attribute .loc\")\n",
    "print(\"    .loc[0:1] pada number_list:\", number_list.loc[0:1])\n",
    "print(\"    .loc[0:1] pada matrix_list:\", matrix_list.loc[0:1])\n",
    "# [11] attribute .iloc\n",
    "print(\"[11] attribute .iloc\")\n",
    "print(\"    iloc[0:1] pada number_list:\", number_list.iloc[0:1])\n",
    "print(\"    iloc[0:1] pada matrix_list:\", matrix_list.iloc[0:1])\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Series & Dataframe from List\n",
    "\n",
    "Untuk membuat Series atau Dataframe bisa dari berbagai macam tipe data container/mapping di python, seperti list dan dictionary, maupun dari numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    a\n",
      "1    1\n",
      "2    3\n",
      "3    5\n",
      "4    c\n",
      "5    d\n",
      "dtype: object\n",
      "     float char   obj char\n",
      "dq     1.0    a     b    c\n",
      "lab    2.5    d     e    f\n",
      "kar    5.0    g     h    i\n",
      "lan    7.5    j  10.5    l\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Creating series from list\n",
    "ex_list = ['a',1,3,5,'c','d']\n",
    "ex_series = pd.Series(ex_list)\n",
    "print(ex_series)\n",
    "# Creating dataframe from list of list\n",
    "ex_list_of_list = [[1, 'a', 'b', 'c'],\n",
    "                   [2.5, 'd', 'e', 'f'],\n",
    "\t\t           [5, 'g', 'h', 'i'],\n",
    "\t\t           [7.5, 'j', 10.5, 'l']]\n",
    "index = ['dq', 'lab', 'kar', 'lan']\n",
    "cols = ['float', 'char', 'obj', 'char']\n",
    "ex_df = pd.DataFrame(ex_list_of_list, index=index, columns=cols)\n",
    "print(ex_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Series & Dataframe from Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    a\n",
      "2    b\n",
      "3    c\n",
      "dtype: object\n",
      "   1  2  4\n",
      "0  a  b  2\n",
      "1  b  c  3\n",
      "2  c  d  z\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Creating series from dictionary\n",
    "dict_series = {'1' : 'a',\n",
    "\t\t\t   '2' : 'b',\n",
    "\t\t\t   '3' : 'c'}\n",
    "ex_series = pd.Series(dict_series)\n",
    "print(ex_series)\n",
    "# Creating dataframe from dictionary\n",
    "df_series = {'1' : ['a', 'b', 'c'],\n",
    "             '2' : ['b', 'c', 'd'], \n",
    "             '4' : [2, 3, 'z']}\n",
    "ex_df = pd.DataFrame(df_series)\n",
    "print(ex_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Series & Dataframe from Numpy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    2\n",
      "2    3\n",
      "3    4\n",
      "4    5\n",
      "5    6\n",
      "6    6\n",
      "7    7\n",
      "dtype: int32\n",
      "   0  1  2   3\n",
      "0  1  2  3   5\n",
      "1  5  6  7   8\n",
      "2  a  b  c  10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Creating series from numpy array (1D)\n",
    "arr_series = np.array([1,2,3,4,5,6,6,7])\n",
    "ex_series = pd.Series(arr_series)\n",
    "print(ex_series)\n",
    "# Creating dataframe from numpy array (2D)\n",
    "arr_df = np.array([[1, 2, 3, 5],\n",
    "                   [5, 6, 7, 8],\n",
    "                   ['a', 'b', 'c', 10]])\n",
    "ex_df = pd.DataFrame(arr_df)\n",
    "print(ex_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas menyediakan berbagai method untuk membaca file tersebut hanya dengan dipanggil method itu, code yang lebih simple dan loading yang lebih, tentu saja output nya dapat berupa Series atau Dataframe.\n",
    "\n",
    "Terdapat sangat banyak file yang dapat dibaca/dapat disimpan oleh Pandas, tapi ada beberapa file yang paling umum dan sering digunakan oleh praktisi data seperti berikut ini:\n",
    "\n",
    "- CSV (Comma Separated Values), antar data dalam satu baris dipisahkan oleh comma, \",\".\n",
    "- TSV (Tab Separated Values), antar data dalam satu baris dipisahkan oleh \"Tab\".\n",
    "- Excel\n",
    "- Google BigQuery\n",
    "- SQL Query\n",
    "- JSON (Java Script Object Notation)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset - CSV dan TSV\n",
    "\n",
    "CSV dan TSV pada hakikatnya adalah tipe data text dengan perbedaan terletak pada pemisah antar data dalam satu baris. Pada file CSV, antar data dalam satu baris dipisahkan oleh comma, \",\". Namun, pada file TSV antar data dalam satu baris dipisahkan oleh \"Tab\".\n",
    "\n",
    "Fungsi .read_csv() digunakan untuk membaca file yang value-nya dipisahkan oleh comma (default), terkadang pemisah value-nya bisa di set ‘\\t’ untuk file tsv (tab separated values).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   order_id  order_date  customer_id             city     province product_id  \\\n",
      "0   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P0648   \n",
      "1   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3826   \n",
      "2   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1508   \n",
      "\n",
      "     brand  quantity  item_price  \n",
      "0  BRAND_C         4     1934000  \n",
      "1  BRAND_V         8      604000  \n",
      "2  BRAND_G        12      747000  \n",
      "   order_id  order_date  customer_id             city     province product_id  \\\n",
      "0   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P0648   \n",
      "1   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3826   \n",
      "2   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1508   \n",
      "\n",
      "     brand  quantity  item_price  \n",
      "0  BRAND_C         4     1934000  \n",
      "1  BRAND_V         8      604000  \n",
      "2  BRAND_G        12      747000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# File CSV\n",
    "df_csv = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_csv.csv\")\n",
    "print(df_csv.head(3)) # Menampilkan 3 data teratas\n",
    "# File TSV\n",
    "df_tsv = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_tsv.tsv\", sep='\\t')\n",
    "print(df_tsv.head(3)) # Menampilkan 3 data teratas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset - Excel\n",
    "File Excel dengan ekstensi *.xls atau *.xlsx cukup banyak digunakan dalam menyimpan data. Pandas juga memiliki fitur untuk membaca file excel.\n",
    "\n",
    "Notes :\n",
    "\n",
    "Dataset : https://storage.googleapis.com/dqlab-dataset/sample_excel.xlsx\n",
    "\n",
    "Fungsi .read_excel() digunakan untuk membaca file excel menjadi dataframe pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\compat\\_optional.py:138\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=136'>137</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=137'>138</a>\u001b[0m     module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(name)\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=138'>139</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/importlib/__init__.py?line=124'>125</a>\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Program%20Files/Python310/lib/importlib/__init__.py?line=125'>126</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\PC\\DQlabtrack\\ADVANCED\\Python\\Data Manipulation with Pandas - Part 1.ipynb Cell 21'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/DQlabtrack/ADVANCED/Python/Data%20Manipulation%20with%20Pandas%20-%20Part%201.ipynb#ch0000020?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/DQlabtrack/ADVANCED/Python/Data%20Manipulation%20with%20Pandas%20-%20Part%201.ipynb#ch0000020?line=1'>2</a>\u001b[0m \u001b[39m# File xlsx dengan data di sheet \"test\"\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/PC/DQlabtrack/ADVANCED/Python/Data%20Manipulation%20with%20Pandas%20-%20Part%201.ipynb#ch0000020?line=2'>3</a>\u001b[0m df_excel \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_excel(\u001b[39m\"\u001b[39;49m\u001b[39mhttps://storage.googleapis.com/dqlab-dataset/sample_excel.xlsx\u001b[39;49m\u001b[39m\"\u001b[39;49m, sheet_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/DQlabtrack/ADVANCED/Python/Data%20Manipulation%20with%20Pandas%20-%20Part%201.ipynb#ch0000020?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(df_excel\u001b[39m.\u001b[39mhead(\u001b[39m5\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/util/_decorators.py?line=304'>305</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/util/_decorators.py?line=305'>306</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/util/_decorators.py?line=306'>307</a>\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/util/_decorators.py?line=307'>308</a>\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/util/_decorators.py?line=308'>309</a>\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/util/_decorators.py?line=309'>310</a>\u001b[0m     )\n\u001b[1;32m--> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/util/_decorators.py?line=310'>311</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\excel\\_base.py:457\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=454'>455</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=455'>456</a>\u001b[0m     should_close \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=456'>457</a>\u001b[0m     io \u001b[39m=\u001b[39m ExcelFile(io, storage_options\u001b[39m=\u001b[39;49mstorage_options, engine\u001b[39m=\u001b[39;49mengine)\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=457'>458</a>\u001b[0m \u001b[39melif\u001b[39;00m engine \u001b[39mand\u001b[39;00m engine \u001b[39m!=\u001b[39m io\u001b[39m.\u001b[39mengine:\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=458'>459</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=459'>460</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mEngine should not be specified when passing \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=460'>461</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=461'>462</a>\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\excel\\_base.py:1419\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=1415'>1416</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mengine \u001b[39m=\u001b[39m engine\n\u001b[0;32m   <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=1416'>1417</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstorage_options \u001b[39m=\u001b[39m storage_options\n\u001b[1;32m-> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_base.py?line=1418'>1419</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reader \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engines[engine](\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_io, storage_options\u001b[39m=\u001b[39;49mstorage_options)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\excel\\_openpyxl.py:524\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=508'>509</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=509'>510</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=510'>511</a>\u001b[0m     filepath_or_buffer: FilePath \u001b[39m|\u001b[39m ReadBuffer[\u001b[39mbytes\u001b[39m],\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=511'>512</a>\u001b[0m     storage_options: StorageOptions \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=512'>513</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=513'>514</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=514'>515</a>\u001b[0m \u001b[39m    Reader using openpyxl engine.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=515'>516</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=521'>522</a>\u001b[0m \u001b[39m        passed to fsspec for appropriate URLs (see ``_get_filepath_or_buffer``)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=522'>523</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=523'>524</a>\u001b[0m     import_optional_dependency(\u001b[39m\"\u001b[39;49m\u001b[39mopenpyxl\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/excel/_openpyxl.py?line=524'>525</a>\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(filepath_or_buffer, storage_options\u001b[39m=\u001b[39mstorage_options)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\compat\\_optional.py:141\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=138'>139</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=139'>140</a>\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=140'>141</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=141'>142</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=142'>143</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# File xlsx dengan data di sheet \"test\"\n",
    "df_excel = pd.read_excel(\"https://storage.googleapis.com/dqlab-dataset/sample_excel.xlsx\", sheet_name=\"test\")\n",
    "print(df_excel.head(5)) # Menampilkan 4 data teratas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset - JSON\n",
    "Method .read_json() digunakan untuk membaca URL API yang formatnya JSON dan mengubahnya menjadi dataframe pandas. Method ini dapat digunakan seperti yang dicontohkan berikut ini:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                data          dt          ts\n",
      "0  {'location': 'US', 'confirmed': 3363056, 'deat...  07-14-2020  1594684800\n",
      "1  {'location': 'Brazil', 'confirmed': 1884967, '...  07-14-2020  1594684800\n",
      "2  {'location': 'India', 'confirmed': 906752, 'de...  07-14-2020  1594684800\n",
      "3  {'location': 'Russia', 'confirmed': 732547, 'd...  07-14-2020  1594684800\n",
      "4  {'location': 'Peru', 'confirmed': 330123, 'dea...  07-14-2020  1594684800\n",
      "5  {'location': 'Chile', 'confirmed': 317657, 'de...  07-14-2020  1594684800\n",
      "6  {'location': 'Mexico', 'confirmed': 304435, 'd...  07-14-2020  1594684800\n",
      "7  {'location': 'United Kingdom', 'confirmed': 29...  07-14-2020  1594684800\n",
      "8  {'location': 'South Africa', 'confirmed': 2877...  07-14-2020  1594684800\n",
      "9  {'location': 'Iran', 'confirmed': 259652, 'dea...  07-14-2020  1594684800\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# File JSON\n",
    "url = \"https://storage.googleapis.com/dqlab-dataset/covid2019-api-herokuapp-v2.json\"\n",
    "df_json = pd.read_json(url)\n",
    "print(df_json.head(10)) # Menampilkan 10 data teratas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset - SQL\n",
    "Fungsi .read_sql() atau .read_sql_query() digunakan untuk membaca query dari database dan translate menjadi pandas dataframe, contoh case ini database sqlite."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contoh penggunaannya:\n",
    "\n",
    "![](images/56.png)\n",
    "\n",
    "Jika menggunakan .read_sql_query\n",
    "\n",
    "![](images/57.png)\n",
    "\n",
    "Output:\n",
    "\n",
    "![](images/58.png)\n",
    "\n",
    "Jika menggunakan .read_sql\n",
    "\n",
    "![](images/59.png)\n",
    "\n",
    "Output:\n",
    "\n",
    "![](images/60.png)\n",
    "\n",
    "Terlihat keduanya menghasilkan output yang sama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\sql.py:761: UserWarning: pandas only support SQLAlchemy connectable(engine/connection) ordatabase string URI or sqlite3 DBAPI2 connectionother DBAPI2 objects are not tested, please consider using SQLAlchemy\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loan_id  account_id        date  amount  duration  payments status\n",
      "0     4959           2  1994-01-05   80952        24    3373.0      A\n",
      "1     4961          19  1996-04-29   30276        12    2523.0      B\n",
      "2     4962          25  1997-12-08   30276        12    2523.0      A\n",
      "3     4967          37  1998-10-14  318480        60    5308.0      D\n",
      "4     4968          38  1998-04-19  110736        48    2307.0      C\n"
     ]
    }
   ],
   "source": [
    "import mysql.connector\n",
    "import pandas as pd\n",
    "\n",
    "my_conn = mysql.connector.connect(host = \"relational.fit.cvut.cz\",\n",
    "                                  port = 3306,\n",
    "                                  user = \"guest\",\n",
    "                                  password = \"relational\",\n",
    "                                  database = \"financial\",\n",
    "                                  use_pure = True)\n",
    "\n",
    "my_tabel = \"SELECT * FROM loan\"\n",
    "\n",
    "df = pd.read_sql(my_tabel, my_conn)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Dataset - Google BigQuery\n",
    "Untuk data yang besar (big data), umumnya digunakan Google BigQuery. Layanan ini dapat digunakan jika telah memiliki Google BigQuery account.\n",
    "\n",
    " \n",
    "\n",
    "Fungsi .read_gbq() digunakan untuk membaca Google BigQuery table menjadi dataframe pandas.\n",
    "\n",
    "![](images/61.png)\n",
    "\n",
    "project_id=\"XXXXXXXX\" adalah ID dari Google BigQuery account.\n",
    "\n",
    "Output-nya:\n",
    "\n",
    "![](images/62.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'pandas-gbq'. pandas-gbq is required to load data from Google BigQuery. See the docs: https://pandas-gbq.readthedocs.io. Use pip or conda to install pandas-gbq.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\compat\\_optional.py:138\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=136'>137</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=137'>138</a>\u001b[0m     module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(name)\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=138'>139</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Program Files\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Program%20Files/Python310/lib/importlib/__init__.py?line=124'>125</a>\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> <a href='file:///c%3A/Program%20Files/Python310/lib/importlib/__init__.py?line=125'>126</a>\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas_gbq'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\PC\\DQlabtrack\\ADVANCED\\Python\\Data Manipulation with Pandas - Part 1.ipynb Cell 28'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/DQlabtrack/ADVANCED/Python/Data%20Manipulation%20with%20Pandas%20-%20Part%201.ipynb#ch0000028?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/DQlabtrack/ADVANCED/Python/Data%20Manipulation%20with%20Pandas%20-%20Part%201.ipynb#ch0000028?line=2'>3</a>\u001b[0m table \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mSELECT * FROM bigquery-public-data.covid19_jhu_case_eu.summary\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/PC/DQlabtrack/ADVANCED/Python/Data%20Manipulation%20with%20Pandas%20-%20Part%201.ipynb#ch0000028?line=4'>5</a>\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_gbq(table, project_id\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mXXXXXXXX\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/PC/DQlabtrack/ADVANCED/Python/Data%20Manipulation%20with%20Pandas%20-%20Part%201.ipynb#ch0000028?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(df)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\gbq.py:170\u001b[0m, in \u001b[0;36mread_gbq\u001b[1;34m(query, project_id, index_col, col_order, reauth, auth_local_webserver, dialect, location, configuration, credentials, use_bqstorage_api, max_results, progress_bar_type)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=25'>26</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mread_gbq\u001b[39m(\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=26'>27</a>\u001b[0m     query: \u001b[39mstr\u001b[39m,\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=27'>28</a>\u001b[0m     project_id: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=38'>39</a>\u001b[0m     progress_bar_type: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=39'>40</a>\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=40'>41</a>\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=41'>42</a>\u001b[0m \u001b[39m    Load data from Google BigQuery.\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=42'>43</a>\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=167'>168</a>\u001b[0m \u001b[39m    DataFrame.to_gbq : Write a DataFrame to Google BigQuery.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=168'>169</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=169'>170</a>\u001b[0m     pandas_gbq \u001b[39m=\u001b[39m _try_import()\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=171'>172</a>\u001b[0m     kwargs: \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mbool\u001b[39m \u001b[39m|\u001b[39m \u001b[39mint\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m] \u001b[39m=\u001b[39m {}\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=173'>174</a>\u001b[0m     \u001b[39m# START: new kwargs.  Don't populate unless explicitly set.\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\io\\gbq.py:22\u001b[0m, in \u001b[0;36m_try_import\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=14'>15</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_try_import\u001b[39m():\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=15'>16</a>\u001b[0m     \u001b[39m# since pandas is a dependency of pandas-gbq\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=16'>17</a>\u001b[0m     \u001b[39m# we need to import on first use\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=17'>18</a>\u001b[0m     msg \u001b[39m=\u001b[39m (\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=18'>19</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mpandas-gbq is required to load data from Google BigQuery. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=19'>20</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mSee the docs: https://pandas-gbq.readthedocs.io.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=20'>21</a>\u001b[0m     )\n\u001b[1;32m---> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=21'>22</a>\u001b[0m     pandas_gbq \u001b[39m=\u001b[39m import_optional_dependency(\u001b[39m\"\u001b[39;49m\u001b[39mpandas_gbq\u001b[39;49m\u001b[39m\"\u001b[39;49m, extra\u001b[39m=\u001b[39;49mmsg)\n\u001b[0;32m     <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/io/gbq.py?line=22'>23</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m pandas_gbq\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\compat\\_optional.py:141\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=138'>139</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mImportError\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=139'>140</a>\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=140'>141</a>\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mImportError\u001b[39;00m(msg)\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=141'>142</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/PC/AppData/Roaming/Python/Python310/site-packages/pandas/compat/_optional.py?line=142'>143</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'pandas-gbq'. pandas-gbq is required to load data from Google BigQuery. See the docs: https://pandas-gbq.readthedocs.io. Use pip or conda to install pandas-gbq."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table = \"SELECT * FROM bigquery-public-data.covid19_jhu_case_eu.summary\"\n",
    "\n",
    "df = pd.read_gbq(table, project_id=\"XXXXXXXX\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Dataset\n",
    "Dalam bekerja sebagai data scientist/analis setelah dilakukan data cleaning dataset yang sudah rapi tentunya disimpan terlebih dahulu ke dalam media penyimpanan.  \n",
    "\n",
    " \n",
    "\n",
    "Pandas menyediakan fitur demikian secara ringkas melalui penerapan method pada dataframe/series yang ditabelkan berikut ini:\n",
    "\n",
    "Method\n",
    "\n",
    "Code\n",
    "\n",
    ".to_csv()\n",
    "\n",
    "→ digunakan untuk export dataframe kembali ke csv atau tsv\t\n",
    "CSV\n",
    "\n",
    "df.to_csv(\"csv1.csv\", index=False)\n",
    "TSV\n",
    "\n",
    "df.to_csv(\"tsv1.tsv\", index=False, sep='\\t')\n",
    ".to_clipboard()\n",
    "\n",
    "→ export dataframe menjadi bahan copy jadi nanti bisa tinggal klik paste di excel atau google sheets\n",
    "\n",
    "df.to_clipboard()\n",
    ".to_excel()\n",
    "\n",
    "→ export dataframe menjadi file excel\n",
    "\n",
    "df_excel.to_excel(\"xlsx1.xlsx\", index=False)\n",
    ".to_gbq()\n",
    "\n",
    "→ export dataframe menjadi table di Google BigQuery\n",
    "\n",
    "df.to_gbq(\"temp.test\", project_id=\"XXXXXX\", if_exists=\"fail\")\n",
    "temp: nama dataset,\n",
    "\n",
    "test: nama table\n",
    "\n",
    "if_exists: ketika tabel dengan dataset.table_name yang sama sudah ada, apa action yang ingin dilakukan\n",
    "\n",
    "(\"fail\": tidak melakukan apa-apa,\n",
    "\n",
    " \"replace': membuang tabel yang sudah ada dan mengganti yang baru,\n",
    "\n",
    " \"append\": menambah baris di tabel tersebut dengan data yang baru\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Head & Tail\n",
    "Seperti yang telah dipelajari sebelumnya bahwa ada method .head yang diterapkan pada suatu variabel bertipe pandas dataframe/series.\n",
    "\n",
    "Method .head ditujukan untuk membatasi tampilan jumlah baris teratas dari dataset. Sementara itu, method .tail ditujukan untuk membatasi jumlah baris terbawah dari dataset.\n",
    "\n",
    "Secara umum kedua method ini memiliki bentuk\n",
    "\n",
    "[nama_dataframe].head(n) \n",
    "dan \n",
    "\n",
    "[nama_dataframe].tail(n)\n",
    "dengan n merupakan jumlah baris yang akan ditampilkan, jika tidak disebutkan n = 5 (sebagai nilai default dari n). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiga data teratas:\n",
      "    order_id  order_date  customer_id             city     province product_id  \\\n",
      "0   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P0648   \n",
      "1   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3826   \n",
      "2   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1508   \n",
      "\n",
      "     brand  quantity  item_price  \n",
      "0  BRAND_C         4     1934000  \n",
      "1  BRAND_V         8      604000  \n",
      "2  BRAND_G        12      747000  \n",
      "Tiga data terbawah:\n",
      "      order_id  order_date  customer_id      city          province product_id  \\\n",
      "98    1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P3354   \n",
      "99    1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P3357   \n",
      "100   1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P0422   \n",
      "\n",
      "       brand  quantity  item_price  \n",
      "98   BRAND_S        24      450000  \n",
      "99   BRAND_S        24      450000  \n",
      "100  BRAND_B         4     1325000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file sample_csv.csv\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_csv.csv\")\n",
    "# Tampilkan 3 data teratas\n",
    "print(\"Tiga data teratas:\\n\", df.head(3))\n",
    "# Tampilkan 3 data terbawah\n",
    "print(\"Tiga data terbawah:\\n\", df.tail(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QUIZ\n",
    "\n",
    "akukan analisis dengan menggunakan BigQuery karena ada beberapa data BigQuery public datasets yang informasinya akurat dan sudah banyak data point-nya sehingga sudah bisa digunakan.\n",
    "\n",
    "Tapi masalahnya, ada beberapa data adhoc yang bergantung tim lain yang belum terlalu melek data dan datanya masih disimpan dalam bentuk CSV.\n",
    "\n",
    "Bagaimana langkah efektif yang dapat diambil untuk melakukan analisis gabungan data dari BigQuery dan CSV?\n",
    "\n",
    " \n",
    "\n",
    "Hint: coba explore BigQuery public datasets dulu, kamu akan dapati data size yang besar (>1juta baris), akan susah kalau harus di export dan dilakukan analisis di excel.\n",
    "\n",
    "JAWABAN\n",
    "\n",
    "(a) Export BigQuery menggunakan pd.read_gbq, kemudian disimpan dalam CSV, lakukan analisis di excel\n",
    "\n",
    "(b) Upload data CSV ke BigQuery, lakukan analisis di dalam BigQuery/export to pandas menggunakan pd.read_gbq\n",
    "\n",
    "(c) Export data BigQuery menggunakan pd.read_gbq as dataframe, kemudian baca file csv menggunakan pd.read_csv dan akhirnya melakukan analisis gabungan di python\n",
    "\n",
    "(b) dan (c)\n",
    "\n",
    "Answers is b ,c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing - Part 1\n",
    "Index merupakan key identifier dari tiap row/column untuk Series atau Dataframe (sifatnya tidak mutable untuk masing-masing value tapi bisa diganti untuk semua value sekaligus).\n",
    "\n",
    "Jika tidak disediakan, pandas akan membuat kolom index default secara otomatis sebagai bilangan bulat (integer) dari 0 sampai range jumlah baris data tersebut.\n",
    "\n",
    "Kolom index dapat terdiri dari:\n",
    "\n",
    "satu kolom (single index), atau\n",
    "multiple kolom (disebut dengan hierarchical indexing).\n",
    "Index dengan multiple kolom ini terjadi karena unique identifier tidak dapat dicapai hanya dengan set index di 1 kolom saja sehingga membutuhkan beberapa kolom yang menjadikan tiap row menjadi unique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing - Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index : RangeIndex(start=0, stop=101, step=1)\n",
      "Columns: Index(['order_id', 'order_date', 'customer_id', 'city', 'province',\n",
      "       'product_id', 'brand', 'quantity', 'item_price'],\n",
      "      dtype='object')\n",
      "     order_id  order_date  customer_id      city          province product_id  \\\n",
      "96    1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P3388   \n",
      "97    1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P3082   \n",
      "98    1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P3354   \n",
      "99    1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P3357   \n",
      "100   1612390  2019-01-01        12681  Makassar  Sulawesi Selatan      P0422   \n",
      "\n",
      "       brand  quantity  item_price  \n",
      "96   BRAND_S        10      450000  \n",
      "97   BRAND_R        18     1045000  \n",
      "98   BRAND_S        24      450000  \n",
      "99   BRAND_S        24      450000  \n",
      "100  BRAND_B         4     1325000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file TSV sample_tsv.tsv\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_tsv.tsv\", sep=\"\\t\")\n",
    "# Index dari df\n",
    "print(\"Index :\", df.index)\n",
    "# Column dari df\n",
    "print(\"Columns:\", df.columns)\n",
    "\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing - Part 3\n",
    "Di sub bab sebelumnya telah dibahas terkait single index, tentunya pada sub bab ini akan bahas multi index atau disebut juga dengan hierarchical indexing.\n",
    "\n",
    "Untuk membuat multi index (hierarchical indexing) dengan pandas diperlukan kolom-kolom mana saja yang perlu disusun agar index dari dataframe menjadi sebuah hirarki yang kemudian dapat dikenali.\n",
    "\n",
    " \n",
    "\n",
    "Pada sub bab sebelumnya telah diberikan nama-nama kolom dari dataframe yang telah dibaca, yaitu:\n",
    "\n",
    "![](images/63.png)\n",
    "\n",
    "dengan output\n",
    "\n",
    "![](images/64.png)\n",
    "\n",
    "Selanjutnya akan membuat multi index dengan menggunakan kolom 'order_id', 'customer_id', 'product_id', dan 'order_date' dengan menggunakan method .set_index(). Mari perhatikan contoh kode yang diberikan berikut ini:\n",
    "\n",
    "![](images/65.png)\n",
    "\n",
    "berikut hasil tampilan dataframe df_x-nya:\n",
    "\n",
    "![](images/66.png)\n",
    "\n",
    "Untuk melihat multi index yang telah diset dapat dilakukan dengan:\n",
    "\n",
    "![](images/67.png)\n",
    "\n",
    "yang memberikan output:\n",
    "\n",
    "![](images/68.png)\n",
    "\n",
    "Perlu diketahui bahwa kumpulan index dari multi index adalah list dari banyak tuples, tuples-nya merupakan kombinasi yang ada dari gabungan index-index tersebut. Dari multi index tersebut juga terdapat atribut levels yang menunjukkan urutan index, dalam case ini 'order_id' > 'customer_id' > 'product_id' > 'order_date'.\n",
    "\n",
    "![](images/69.png)\n",
    "\n",
    "yang menghasilkan output berupa:\n",
    "\n",
    "![](images/70.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_date : Index(['2019-01-01'], dtype='object', name='order_date')\n",
      "city : Index(['Bogor', 'Jakarta Pusat', 'Jakarta Selatan', 'Jakarta Utara',\n",
      "       'Makassar', 'Malang', 'Surabaya', 'Tangerang'],\n",
      "      dtype='object', name='city')\n",
      "customer_id : Int64Index([12681, 13963, 15649, 17091, 17228, 17450, 17470, 17511, 17616,\n",
      "            18055],\n",
      "           dtype='int64', name='customer_id')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file TSV sample_tsv.tsv\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_tsv.tsv\", sep=\"\\t\")\n",
    "# Set multi index df\n",
    "df_x = df.set_index(['order_date', 'city', 'customer_id'])\n",
    "# Print nama dan level dari multi index\n",
    "for nama, level in zip(df_x.index.names, df_x.index.levels):\n",
    "    print(nama,':',level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reset Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           day number week type\n",
      "Monday              1   weekday\n",
      "Tuesday             2   weekday\n",
      "Wednesday           3   weekday\n",
      "Thursday            4   weekday\n",
      "Friday              5   weekday\n",
      "Saturday            6   weekend\n",
      "Sunday              7   weekend\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({ \"day number\" : [i for i in range(1,8)],\n",
    "                    \"week type\" : [\"weekday\" for i in range (5)] + [\"weekend\" for i in range (2)]}, index=[\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"])\n",
    "df.reset_index(drop=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing - Part 4\n",
    "Terdapat beberapa cara untuk membuat index, salah satunya adalah seperti yang telah dilakukan pada sub bab sebelumnya dengan menggunakan method .set_index().\n",
    "\n",
    "Di sub bab ini akan menggunakan assignment untuk menset index dari suatu dataframe. Untuk itu file \"sample_excel.xlsx\" yang digunakan. Perhatikan code berikut!\n",
    "\n",
    "![](images/71.png)\n",
    "\n",
    "maka Outputnya\n",
    "\n",
    "![](images/72.png)\n",
    "\n",
    "Note:\n",
    "\n",
    "- Cara yang ditunjukkan oleh baris ketujuh (ke-7) pada code editor di atas hanya berlaku jika index yang di-assign tersebut memiliki panjang yang sama dengan jumlah \n",
    "baris dari dataframe.\n",
    "- Jika ingin kembalikan dataframe ke index default-nya yaitu dari 0 s/d jumlah baris data - 1, maka dapat menggunakan method .reset_index(drop=True), argument drop=True bertujuan untuk menghapus index lama. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe awal:\n",
      "    order_id  order_date  customer_id             city     province product_id  \\\n",
      "0   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P0648   \n",
      "1   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3826   \n",
      "2   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1508   \n",
      "3   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P0520   \n",
      "4   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1513   \n",
      "5   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3911   \n",
      "6   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1780   \n",
      "7   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P3132   \n",
      "8   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P1342   \n",
      "9   1612339  2019-01-01        18055  Jakarta Selatan  DKI Jakarta      P2556   \n",
      "\n",
      "     brand  quantity  item_price  \n",
      "0  BRAND_C         4     1934000  \n",
      "1  BRAND_V         8      604000  \n",
      "2  BRAND_G        12      747000  \n",
      "3  BRAND_B        12      450000  \n",
      "4  BRAND_G         3     1500000  \n",
      "5  BRAND_V         3     2095000  \n",
      "6  BRAND_H         3     2095000  \n",
      "7  BRAND_S         3     1745000  \n",
      "8  BRAND_F         6     1045000  \n",
      "9  BRAND_P         6     1045000  \n",
      "Dataframe dengan index baru:\n",
      "                order_id  order_date  customer_id             city  \\\n",
      "Pesanan ke-1    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-2    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-3    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-4    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-5    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-6    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-7    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-8    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-9    1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "Pesanan ke-10   1612339  2019-01-01        18055  Jakarta Selatan   \n",
      "\n",
      "                  province product_id    brand  quantity  item_price  \n",
      "Pesanan ke-1   DKI Jakarta      P0648  BRAND_C         4     1934000  \n",
      "Pesanan ke-2   DKI Jakarta      P3826  BRAND_V         8      604000  \n",
      "Pesanan ke-3   DKI Jakarta      P1508  BRAND_G        12      747000  \n",
      "Pesanan ke-4   DKI Jakarta      P0520  BRAND_B        12      450000  \n",
      "Pesanan ke-5   DKI Jakarta      P1513  BRAND_G         3     1500000  \n",
      "Pesanan ke-6   DKI Jakarta      P3911  BRAND_V         3     2095000  \n",
      "Pesanan ke-7   DKI Jakarta      P1780  BRAND_H         3     2095000  \n",
      "Pesanan ke-8   DKI Jakarta      P3132  BRAND_S         3     1745000  \n",
      "Pesanan ke-9   DKI Jakarta      P1342  BRAND_F         6     1045000  \n",
      "Pesanan ke-10  DKI Jakarta      P2556  BRAND_P         6     1045000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file sample_tsv.tsv untuk 10 baris pertama saja\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_tsv.tsv\", sep=\"\\t\", nrows=10)\n",
    "# Cetak data frame awal\n",
    "print(\"Dataframe awal:\\n\", df)\n",
    "# Set index baru\n",
    "df.index = [\"Pesanan ke-\" + str(i) for i in range(1, 11)]\n",
    "# Cetak data frame dengan index baru\n",
    "print(\"Dataframe dengan index baru:\\n\", df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing - Part 5\n",
    "Jika file yang akan dibaca melalui penggunaan library pandas dapat di-preview terlebih dahulu struktur datanya maka melalui fungsi yang ditujukan untuk membaca file dapat diset mana kolom yang akan dijadikan index.\n",
    "\n",
    " \n",
    "\n",
    "Fitur ini telah dimiliki oleh setiap fungsi yang digunakan dalam membaca data dengan pandas, yaitu penggunaan argumen index_col pada fungsi yang dimaksud. Untuk jelasnya dapat diperhatikan pada kode berikut ini.\n",
    "\n",
    "![](images/73.png)\n",
    "\n",
    "Dari dataset sample_csv.csv, sample_tsv.tsv, atau sample_excel.xlsx sudah tahu bahwa kolom dataset adalah 'order_id'; 'order_date'; 'customer_id'; 'city'; 'province'; 'product_id'; 'brand'; 'quantity'; and 'item_price'. Sehingga kode di atas digunakan langsung kolom 'order_date' pada saat membaca file-nya.\n",
    "\n",
    "maka outputnya :\n",
    "\n",
    "![](images/74.png)\n",
    "\n",
    "Terlihat bahwa kolom order_date sudah jadi index, dan tentunya jumlah kolom dataframe berkurang satu, yaitu menjadi delapan kolom.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe:\n",
      "                      customer_id             city     province product_id  \\\n",
      "order_date order_id                                                         \n",
      "2019-01-01 1612339         18055  Jakarta Selatan  DKI Jakarta      P0648   \n",
      "           1612339         18055  Jakarta Selatan  DKI Jakarta      P3826   \n",
      "           1612339         18055  Jakarta Selatan  DKI Jakarta      P1508   \n",
      "           1612339         18055  Jakarta Selatan  DKI Jakarta      P0520   \n",
      "           1612339         18055  Jakarta Selatan  DKI Jakarta      P1513   \n",
      "           1612339         18055  Jakarta Selatan  DKI Jakarta      P3911   \n",
      "           1612339         18055  Jakarta Selatan  DKI Jakarta      P1780   \n",
      "           1612339         18055  Jakarta Selatan  DKI Jakarta      P3132   \n",
      "\n",
      "                       brand  quantity  item_price  \n",
      "order_date order_id                                 \n",
      "2019-01-01 1612339   BRAND_C         4     1934000  \n",
      "           1612339   BRAND_V         8      604000  \n",
      "           1612339   BRAND_G        12      747000  \n",
      "           1612339   BRAND_B        12      450000  \n",
      "           1612339   BRAND_G         3     1500000  \n",
      "           1612339   BRAND_V         3     2095000  \n",
      "           1612339   BRAND_H         3     2095000  \n",
      "           1612339   BRAND_S         3     1745000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file sample_tsv.tsv dan set lah index_col sesuai instruksi\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_tsv.tsv\", sep=\"\\t\", index_col=[\"order_date\", \"order_id\"])\n",
    "# Cetak data frame untuk 8 data teratas\n",
    "print(\"Dataframe:\\n\", df.head(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['name', 'num']\n"
     ]
    }
   ],
   "source": [
    "df_week = pd.DataFrame({'day_number':[1,2,3,4,5,6,7],\n",
    "                        'week_type':['weekday' for i in range(5)] + ['weekend' for i in range(2)]\n",
    "                       })\n",
    "df_week_ix = ['Mon','Tue','Wed','Thu','Fri','Sat','Sun']\n",
    "df_week.index = [df_week_ix, df_week['day_number'].to_list()]\n",
    "df_week.index.names = ['name','num']\n",
    "print(df_week.index.names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing - Part 1\n",
    "Seperti artinya slicing adalah cara untuk melakukan filter ke dataframe/series berdasarkan kriteria tertentu dari nilai kolomnya ataupun kriteria index-nya.\n",
    "\n",
    "Terdapat 2 cara paling terkenal untuk slicing dataframe, yaitu dengan menggunakan method .loc dan .iloc pada variabel bertipe pandas DataFrame/Series. Method .iloc ditujukan untuk proses slicing berdasarkan index berupa nilai integer tertentu. Akan tetapi akan lebih sering menggunakan dengan method .loc karena lebih fleksibel. \n",
    "\n",
    " \n",
    "\n",
    "Mari ikuti ilustrasi berikut ini.\n",
    "\n",
    "Dataset belum dilakukan indexing, jadi slicing berdasarkan nilai kolomnya. Untuk itu \"sample_csv.csv\" dibaca kembali dan dipraktikkan metode .loc[] dengan mengambil tanggal 1 Januari 2019 dari kolom order_date dan product_id nya adalah P2154 dan P2556.\n",
    "\n",
    "![](images/75.png)\n",
    "\n",
    "Output\n",
    "\n",
    "![](images/76.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        num_legs  num_wings\n",
      "falcon     False      False\n",
      "dog         True       True\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'num_legs': [2, 4], 'num_wings': [2, 0]},\n",
    "                  index=['falcon', 'dog'])\n",
    "print(df.isin([0, 4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice langsung berdasarkan kolom:\n",
      " Empty DataFrame\n",
      "Columns: [order_id, order_date, customer_id, city, province, product_id, brand, quantity, item_price]\n",
      "Index: []\n",
      "     order_id  order_date  customer_id             city          province  \\\n",
      "0     1612339  2019-01-01        18055  Jakarta Selatan       DKI Jakarta   \n",
      "1     1612339  2019-01-01        18055  Jakarta Selatan       DKI Jakarta   \n",
      "2     1612339  2019-01-01        18055  Jakarta Selatan       DKI Jakarta   \n",
      "3     1612339  2019-01-01        18055  Jakarta Selatan       DKI Jakarta   \n",
      "4     1612339  2019-01-01        18055  Jakarta Selatan       DKI Jakarta   \n",
      "..        ...         ...          ...              ...               ...   \n",
      "96    1612390  2019-01-01        12681         Makassar  Sulawesi Selatan   \n",
      "97    1612390  2019-01-01        12681         Makassar  Sulawesi Selatan   \n",
      "98    1612390  2019-01-01        12681         Makassar  Sulawesi Selatan   \n",
      "99    1612390  2019-01-01        12681         Makassar  Sulawesi Selatan   \n",
      "100   1612390  2019-01-01        12681         Makassar  Sulawesi Selatan   \n",
      "\n",
      "    product_id    brand  quantity  item_price  \n",
      "0        P0648  BRAND_C         4     1934000  \n",
      "1        P3826  BRAND_V         8      604000  \n",
      "2        P1508  BRAND_G        12      747000  \n",
      "3        P0520  BRAND_B        12      450000  \n",
      "4        P1513  BRAND_G         3     1500000  \n",
      "..         ...      ...       ...         ...  \n",
      "96       P3388  BRAND_S        10      450000  \n",
      "97       P3082  BRAND_R        18     1045000  \n",
      "98       P3354  BRAND_S        24      450000  \n",
      "99       P3357  BRAND_S        24      450000  \n",
      "100      P0422  BRAND_B         4     1325000  \n",
      "\n",
      "[101 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file sample_csv.csv\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_csv.csv\")\n",
    "# Slice langsung berdasarkan kolom\n",
    "df_slice = df.loc[(df[\"customer_id\"] == 18055) &\n",
    "\t\t          (df[\"product_id\"].isin([\"P0029\", \"P0040\", \"P0041\", \"P0116\", \"P0117\"]))\n",
    "\t\t\t\t ]\n",
    "print(\"Slice langsung berdasarkan kolom:\\n\", df_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    customer_id product_id\n",
      "0         18055      P0029\n",
      "1         18098      P0040\n",
      "2         19053      P0041\n",
      "3         18055      P0116\n",
      "4         19053      P0117\n",
      "5         18055      P0012\n",
      "6         18055      P0044\n",
      "7         18055      P0040\n",
      "8         18055      P0041\n",
      "9         18055      P0116\n",
      "10        18098      P0029\n",
      "11        18055      P0040\n",
      "12        18098      P0041\n",
      "13        19053      P0116\n",
      "14        18055      P0117\n",
      "15        18098      P0012\n",
      "Slice langsung berdasarkan kolom:\n",
      "     customer_id product_id\n",
      "0         18055      P0029\n",
      "3         18055      P0116\n",
      "7         18055      P0040\n",
      "8         18055      P0041\n",
      "9         18055      P0116\n",
      "11        18055      P0040\n",
      "14        18055      P0117\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'customer_id' : [18055, 18098, 19053 , 18055, 19053, 18055, 18055, 18055, 18055,18055\n",
    "                    , 18098, 18055, 18098, 19053, 18055, 18098], \n",
    "                    'product_id' : ['P0029', 'P0040', 'P0041', 'P0116', 'P0117', 'P0012', 'P0044', 'P0040',\n",
    "                    'P0041', 'P0116', 'P0029', 'P0040', 'P0041', 'P0116', 'P0117', 'P0012']})\n",
    "\n",
    "\n",
    "df_slice = df.loc[(df[\"customer_id\"] == 18055) &\n",
    "\t\t          (df[\"product_id\"].isin([\"P0029\", \"P0040\", \"P0041\", \"P0116\", \"P0117\"]))\n",
    "\t\t\t\t ]\n",
    "\n",
    "print(df)\n",
    "print(\"Slice langsung berdasarkan kolom:\\n\", df_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing - Part 2\n",
    "Dalam sub bab sebelumnya telah mempelajari bagaimana melakukan slicing/filtering dataset dengan menggunakan method .loc pada kolom dataset.\n",
    "\n",
    "Sekarang, menerapkan berdasarkan index. Tentu syaratnya adalah dataset sudah dilakukan indexing terlebih dahulu melalui penerapan method .set_index \n",
    "\n",
    " \n",
    "\n",
    "Cara 1: Gunakan method .loc seperti yang dicontohkan berikut:\n",
    "\n",
    "![](images/77.png)\n",
    "\n",
    "Output cara 1:\n",
    "\n",
    "![](images/78.png)\n",
    "\n",
    "Cara 2: Gunakan pd.IndexSlice sebagai varaibel untuk melakukan slicing index\n",
    "\n",
    "![](images/79.png)\n",
    "\n",
    "Output cara 2:\n",
    "\n",
    "![](images/80.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slice df:\n",
      "                                 customer_id             city     province  \\\n",
      "order_date order_id product_id                                              \n",
      "2019-01-01 1612339  P2154             18055  Jakarta Selatan  DKI Jakarta   \n",
      "                    P2159             18055  Jakarta Selatan  DKI Jakarta   \n",
      "\n",
      "                                  brand  quantity  item_price  \n",
      "order_date order_id product_id                                 \n",
      "2019-01-01 1612339  P2154       BRAND_M         4     1745000  \n",
      "                    P2159       BRAND_M        24      310000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Baca file sample_csv.csv\n",
    "df = pd.read_csv(\"https://storage.googleapis.com/dqlab-dataset/sample_csv.csv\")\n",
    "# Set index dari df sesuai instruksi\n",
    "df = df.set_index([\"order_date\", \"order_id\", \"product_id\"])\n",
    "# Slice sesuai intruksi\n",
    "df_slice = df.loc[(\"2019-01-01\", 1612339, [\"P2154\", \"P2159\"]),:]\n",
    "print(\"Slice df:\\n\", df_slice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quiz\n",
    "\n",
    "sample_csv = pd.read_csv('sample_csv.csv')\n",
    "\n",
    "sample_csv = sample_csv.set_index(['province','product_id'])\n",
    "\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "sample_csv.sort_index().loc[idx['Sulawesi Selatan', 'P3082':'P3357'], :]\n",
    "\n",
    "Code mana yang akan menghasilkan semua kolom, dengan filter province = ‘Sulawesi Selatan’ dan product_id dari ‘P3082’ sampai ‘P3357’?"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
